{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ee97189",
   "metadata": {},
   "source": [
    "# Vertex AI Pipelines - End-to-End MLOps Orchestration\n",
    "\n",
    "This notebook demonstrates comprehensive pipeline orchestration for MLOps workflows using both simple local execution and advanced Vertex AI Pipelines.\n",
    "\n",
    "## Features Covered\n",
    "- Simple local pipeline execution\n",
    "- Advanced Vertex AI Pipelines integration \n",
    "- End-to-end MLOps workflow orchestration\n",
    "- Pipeline monitoring and management\n",
    "- Component composition and reusability\n",
    "\n",
    "**Author:** MLOps Team  \n",
    "**Version:** 1.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b5fd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "print(\"üì¶ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f99b32",
   "metadata": {},
   "source": [
    "## 1. Pipeline Orchestration Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f57f859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pipeline orchestration modules\n",
    "from src.pipelines import (\n",
    "    SimplePipeline, LocalPipelineRunner, SimplePipelineConfig,\n",
    "    PipelineStep, PipelineResult, StepStatus, PipelineType,\n",
    "    create_pipeline_runner, run_sample_pipeline\n",
    ")\n",
    "\n",
    "from src.config import Config\n",
    "from src.utils import setup_logging\n",
    "\n",
    "# Initialize configuration\n",
    "config = Config()\n",
    "logger = setup_logging(__name__)\n",
    "\n",
    "print(\"üöÄ Pipeline orchestration modules imported\")\n",
    "print(f\"üìÅ Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b21613",
   "metadata": {},
   "source": [
    "## 2. Simple Local Pipeline Execution\n",
    "\n",
    "First, let's demonstrate simple local pipeline execution for development and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e641b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline runner\n",
    "runner = create_pipeline_runner()\n",
    "\n",
    "# Configure simple training pipeline\n",
    "training_config = SimplePipelineConfig(\n",
    "    name=\"iris_training_pipeline\",\n",
    "    description=\"Iris classification training pipeline\",\n",
    "    pipeline_type=PipelineType.TRAINING,\n",
    "    parameters={\n",
    "        'algorithm': 'random_forest',\n",
    "        'output_model_path': './models/iris_pipeline_model.joblib',\n",
    "        'random_state': 42\n",
    "    },\n",
    "    fail_fast=True,\n",
    "    enable_retries=True\n",
    ")\n",
    "\n",
    "print(f\"üìã Training pipeline configured: {training_config.name}\")\n",
    "print(f\"üéØ Algorithm: {training_config.parameters['algorithm']}\")\n",
    "print(f\"üíæ Output path: {training_config.parameters['output_model_path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517f3bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training pipeline\n",
    "training_pipeline = runner.create_training_pipeline(training_config)\n",
    "\n",
    "print(f\"üèóÔ∏è  Pipeline created with {len(training_pipeline.steps)} steps:\")\n",
    "for i, step in enumerate(training_pipeline.steps, 1):\n",
    "    print(f\"   {i}. {step.name}: {step.description}\")\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è  Pipeline configuration:\")\n",
    "print(f\"   - Fail fast: {training_config.fail_fast}\")\n",
    "print(f\"   - Retries enabled: {training_config.enable_retries}\")\n",
    "print(f\"   - Pipeline type: {training_config.pipeline_type.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3c77b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute training pipeline\n",
    "print(\"üöÄ Starting pipeline execution...\")\n",
    "start_time = datetime.now()\n",
    "\n",
    "result = runner.run_pipeline(training_config.name)\n",
    "\n",
    "execution_time = datetime.now() - start_time\n",
    "\n",
    "print(f\"\\n‚úÖ Pipeline execution completed!\")\n",
    "print(f\"üìä Results:\")\n",
    "print(f\"   - Status: {result.status}\")\n",
    "print(f\"   - Steps completed: {result.steps_completed}/{result.steps_total}\")\n",
    "print(f\"   - Success rate: {result.success_rate:.1%}\")\n",
    "print(f\"   - Duration: {result.duration_seconds:.2f}s\")\n",
    "print(f\"   - Execution time: {execution_time.total_seconds():.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be34be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display pipeline metrics\n",
    "if result.metrics:\n",
    "    print(\"üìà Model Performance Metrics:\")\n",
    "    for metric_name, value in result.metrics.items():\n",
    "        print(f\"   - {metric_name.title()}: {value:.4f}\")\n",
    "    \n",
    "    # Create metrics visualization\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    metrics_df = pd.DataFrame([\n",
    "        {'Metric': k.title(), 'Value': v} \n",
    "        for k, v in result.metrics.items()\n",
    "    ])\n",
    "    \n",
    "    bars = ax.bar(metrics_df['Metric'], metrics_df['Value'], \n",
    "                  color=['#3498db', '#e74c3c', '#2ecc71', '#f39c12'])\n",
    "    \n",
    "    ax.set_title('Model Performance Metrics', fontsize=16, fontweight='bold')\n",
    "    ax.set_ylabel('Score', fontsize=12)\n",
    "    ax.set_ylim(0, 1)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                f'{height:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  No metrics available in pipeline result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0838c9",
   "metadata": {},
   "source": [
    "## 3. Deployment Pipeline\n",
    "\n",
    "Now let's create and execute a deployment pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e95301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure deployment pipeline\n",
    "deployment_config = SimplePipelineConfig(\n",
    "    name=\"iris_deployment_pipeline\",\n",
    "    description=\"Iris model deployment pipeline\",\n",
    "    pipeline_type=PipelineType.DEPLOYMENT,\n",
    "    parameters={\n",
    "        'model_path': './models/iris_pipeline_model.joblib',\n",
    "        'endpoint_name': 'iris-classification-endpoint',\n",
    "        'machine_type': 'n1-standard-2',\n",
    "        'min_replicas': 1,\n",
    "        'max_replicas': 3\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create deployment pipeline\n",
    "deployment_pipeline = runner.create_deployment_pipeline(deployment_config)\n",
    "\n",
    "print(f\"üö¢ Deployment pipeline created with {len(deployment_pipeline.steps)} steps:\")\n",
    "for i, step in enumerate(deployment_pipeline.steps, 1):\n",
    "    print(f\"   {i}. {step.name}: {step.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7e8021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute deployment pipeline\n",
    "print(\"üöÄ Starting deployment pipeline...\")\n",
    "\n",
    "deployment_result = runner.run_pipeline(deployment_config.name)\n",
    "\n",
    "print(f\"\\n‚úÖ Deployment pipeline completed!\")\n",
    "print(f\"üìä Results:\")\n",
    "print(f\"   - Status: {deployment_result.status}\")\n",
    "print(f\"   - Steps completed: {deployment_result.steps_completed}/{deployment_result.steps_total}\")\n",
    "print(f\"   - Success rate: {deployment_result.success_rate:.1%}\")\n",
    "print(f\"   - Duration: {deployment_result.duration_seconds:.2f}s\")\n",
    "\n",
    "if deployment_result.outputs:\n",
    "    print(f\"\\nüîó Deployment Outputs:\")\n",
    "    for key, value in deployment_result.outputs.items():\n",
    "        if isinstance(value, str) and len(value) < 100:\n",
    "            print(f\"   - {key}: {value}\")\n",
    "        else:\n",
    "            print(f\"   - {key}: <{type(value).__name__}>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6566ff5d",
   "metadata": {},
   "source": [
    "## 4. Full End-to-End MLOps Pipeline\n",
    "\n",
    "Let's create and execute a complete end-to-end MLOps pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390b680a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure full MLOps pipeline\n",
    "mlops_config = SimplePipelineConfig(\n",
    "    name=\"full_mlops_pipeline\",\n",
    "    description=\"Complete end-to-end MLOps pipeline\",\n",
    "    pipeline_type=PipelineType.FULL_MLOPS,\n",
    "    parameters={\n",
    "        'data_source': 'iris_dataset',\n",
    "        'algorithm': 'random_forest',\n",
    "        'deploy_model': True,\n",
    "        'endpoint_name': 'mlops-iris-endpoint',\n",
    "        'model_validation_threshold': 0.85,\n",
    "        'enable_monitoring': True\n",
    "    },\n",
    "    fail_fast=False,  # Continue on errors for demo\n",
    "    enable_retries=True\n",
    ")\n",
    "\n",
    "# Create full MLOps pipeline\n",
    "mlops_pipeline = runner.create_full_mlops_pipeline(mlops_config)\n",
    "\n",
    "print(f\"üåü Full MLOps pipeline created with {len(mlops_pipeline.steps)} steps:\")\n",
    "for i, step in enumerate(mlops_pipeline.steps, 1):\n",
    "    print(f\"   {i}. {step.name}: {step.description}\")\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è  Pipeline features:\")\n",
    "print(f\"   - Model deployment: {mlops_config.parameters['deploy_model']}\")\n",
    "print(f\"   - Monitoring: {mlops_config.parameters['enable_monitoring']}\")\n",
    "print(f\"   - Algorithm: {mlops_config.parameters['algorithm']}\")\n",
    "print(f\"   - Validation threshold: {mlops_config.parameters['model_validation_threshold']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee131330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute full MLOps pipeline with progress tracking\n",
    "print(\"üöÄ Starting full MLOps pipeline...\")\n",
    "print(\"üìä Progress will be tracked step by step\\n\")\n",
    "\n",
    "# Execute pipeline\n",
    "mlops_result = runner.run_pipeline(mlops_config.name)\n",
    "\n",
    "print(f\"\\nüéâ Full MLOps pipeline completed!\")\n",
    "print(f\"üìä Final Results:\")\n",
    "print(f\"   - Overall Status: {mlops_result.status.upper()}\")\n",
    "print(f\"   - Steps completed: {mlops_result.steps_completed}/{mlops_result.steps_total}\")\n",
    "print(f\"   - Success rate: {mlops_result.success_rate:.1%}\")\n",
    "print(f\"   - Total duration: {mlops_result.duration_seconds:.2f}s\")\n",
    "print(f\"   - Start time: {mlops_result.start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"   - End time: {mlops_result.end_time.strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad66ab47",
   "metadata": {},
   "source": [
    "## 5. Pipeline Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fb3fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze pipeline performance\n",
    "pipeline_results = {\n",
    "    'Training Pipeline': result,\n",
    "    'Deployment Pipeline': deployment_result,\n",
    "    'Full MLOps Pipeline': mlops_result\n",
    "}\n",
    "\n",
    "# Create performance comparison\n",
    "performance_data = []\n",
    "for name, res in pipeline_results.items():\n",
    "    performance_data.append({\n",
    "        'Pipeline': name,\n",
    "        'Status': res.status,\n",
    "        'Steps Completed': res.steps_completed,\n",
    "        'Total Steps': res.steps_total,\n",
    "        'Success Rate': res.success_rate,\n",
    "        'Duration (s)': res.duration_seconds\n",
    "    })\n",
    "\n",
    "performance_df = pd.DataFrame(performance_data)\n",
    "print(\"üìä Pipeline Performance Comparison:\")\n",
    "print(performance_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8941cfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize pipeline performance\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Success rate comparison\n",
    "axes[0,0].bar(performance_df['Pipeline'], performance_df['Success Rate'], \n",
    "              color=['#3498db', '#e74c3c', '#2ecc71'])\n",
    "axes[0,0].set_title('Pipeline Success Rates', fontweight='bold')\n",
    "axes[0,0].set_ylabel('Success Rate')\n",
    "axes[0,0].set_ylim(0, 1.1)\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Duration comparison\n",
    "axes[0,1].bar(performance_df['Pipeline'], performance_df['Duration (s)'], \n",
    "              color=['#f39c12', '#9b59b6', '#1abc9c'])\n",
    "axes[0,1].set_title('Pipeline Execution Duration', fontweight='bold')\n",
    "axes[0,1].set_ylabel('Duration (seconds)')\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Steps completion\n",
    "x = range(len(performance_df))\n",
    "width = 0.35\n",
    "axes[1,0].bar([i - width/2 for i in x], performance_df['Steps Completed'], width, \n",
    "              label='Completed', color='#2ecc71')\n",
    "axes[1,0].bar([i + width/2 for i in x], performance_df['Total Steps'], width, \n",
    "              label='Total', color='#34495e')\n",
    "axes[1,0].set_title('Pipeline Steps Completion', fontweight='bold')\n",
    "axes[1,0].set_ylabel('Number of Steps')\n",
    "axes[1,0].set_xticks(x)\n",
    "axes[1,0].set_xticklabels(performance_df['Pipeline'], rotation=45)\n",
    "axes[1,0].legend()\n",
    "\n",
    "# Pipeline status pie chart\n",
    "status_counts = performance_df['Status'].value_counts()\n",
    "colors = ['#2ecc71' if status == 'completed' else '#e74c3c' for status in status_counts.index]\n",
    "axes[1,1].pie(status_counts.values, labels=status_counts.index, autopct='%1.1f%%',\n",
    "              colors=colors, startangle=90)\n",
    "axes[1,1].set_title('Pipeline Status Distribution', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481d067b",
   "metadata": {},
   "source": [
    "## 6. Pipeline Management and Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e1f15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all pipelines and their results\n",
    "all_pipelines = runner.list_pipelines()\n",
    "print(f\"üìã Registered Pipelines ({len(all_pipelines)}):\")\n",
    "\n",
    "for i, pipeline_name in enumerate(all_pipelines, 1):\n",
    "    result = runner.get_pipeline_result(pipeline_name)\n",
    "    if result:\n",
    "        print(f\"   {i}. {pipeline_name}\")\n",
    "        print(f\"      - Status: {result.status}\")\n",
    "        print(f\"      - Duration: {result.duration_seconds:.2f}s\")\n",
    "        print(f\"      - Success Rate: {result.success_rate:.1%}\")\n",
    "        if result.error_message:\n",
    "            print(f\"      - Error: {result.error_message[:100]}...\")\n",
    "    else:\n",
    "        print(f\"   {i}. {pipeline_name} (No results available)\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d6cc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline step analysis\n",
    "if len(mlops_pipeline.steps) > 0:\n",
    "    print(\"üîç Detailed Step Analysis (Full MLOps Pipeline):\")\n",
    "    \n",
    "    step_analysis = []\n",
    "    for i, step in enumerate(mlops_pipeline.steps, 1):\n",
    "        duration = 0\n",
    "        if step.start_time and step.end_time:\n",
    "            duration = (step.end_time - step.start_time).total_seconds()\n",
    "        \n",
    "        step_analysis.append({\n",
    "            'Step': f\"{i}. {step.name}\",\n",
    "            'Status': step.status.value,\n",
    "            'Duration (s)': f\"{duration:.2f}\",\n",
    "            'Retries': step.retry_count,\n",
    "            'Description': step.description[:50] + '...' if len(step.description) > 50 else step.description\n",
    "        })\n",
    "    \n",
    "    step_df = pd.DataFrame(step_analysis)\n",
    "    print(step_df.to_string(index=False))\n",
    "    \n",
    "    # Step status visualization\n",
    "    status_colors = {\n",
    "        'completed': '#2ecc71',\n",
    "        'failed': '#e74c3c',\n",
    "        'pending': '#f39c12',\n",
    "        'running': '#3498db',\n",
    "        'skipped': '#95a5a6'\n",
    "    }\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    step_statuses = [step.status.value for step in mlops_pipeline.steps]\n",
    "    colors = [status_colors.get(status, '#34495e') for status in step_statuses]\n",
    "    \n",
    "    bars = ax.bar(range(len(step_statuses)), [1] * len(step_statuses), color=colors)\n",
    "    ax.set_title('Pipeline Step Status Overview', fontsize=16, fontweight='bold')\n",
    "    ax.set_xlabel('Pipeline Steps')\n",
    "    ax.set_ylabel('Status')\n",
    "    ax.set_xticks(range(len(mlops_pipeline.steps)))\n",
    "    ax.set_xticklabels([f\"{i+1}. {step.name}\" for i, step in enumerate(mlops_pipeline.steps)], \n",
    "                       rotation=45, ha='right')\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    # Add legend\n",
    "    unique_statuses = list(set(step_statuses))\n",
    "    legend_elements = [plt.Rectangle((0,0),1,1, facecolor=status_colors.get(status, '#34495e'), \n",
    "                                   label=status.title()) for status in unique_statuses]\n",
    "    ax.legend(handles=legend_elements, loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b176e73",
   "metadata": {},
   "source": [
    "## 7. Advanced Pipeline Features\n",
    "\n",
    "Demonstrate advanced pipeline features and integrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef7ab11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom pipeline step example\n",
    "def custom_data_quality_check(**kwargs):\n",
    "    \"\"\"Custom data quality check step.\"\"\"\n",
    "    logger.info(\"Executing custom data quality check\")\n",
    "    \n",
    "    data = kwargs.get('data', kwargs.get('processed_data'))\n",
    "    if data is None:\n",
    "        raise ValueError(\"No data provided for quality check\")\n",
    "    \n",
    "    # Perform quality checks\n",
    "    quality_metrics = {\n",
    "        'null_percentage': (data.isnull().sum().sum() / (len(data) * len(data.columns))) * 100,\n",
    "        'duplicate_percentage': (data.duplicated().sum() / len(data)) * 100,\n",
    "        'data_completeness': ((len(data) * len(data.columns) - data.isnull().sum().sum()) / \n",
    "                             (len(data) * len(data.columns))) * 100\n",
    "    }\n",
    "    \n",
    "    # Quality score\n",
    "    quality_score = (\n",
    "        (100 - quality_metrics['null_percentage']) * 0.4 +\n",
    "        (100 - quality_metrics['duplicate_percentage']) * 0.3 +\n",
    "        quality_metrics['data_completeness'] * 0.3\n",
    "    ) / 100\n",
    "    \n",
    "    quality_passed = quality_score > 0.8  # 80% threshold\n",
    "    \n",
    "    return {\n",
    "        'quality_metrics': quality_metrics,\n",
    "        'quality_score': quality_score,\n",
    "        'quality_passed': quality_passed,\n",
    "        'data': data  # Pass through data\n",
    "    }\n",
    "\n",
    "# Create custom pipeline with quality check\n",
    "custom_config = SimplePipelineConfig(\n",
    "    name=\"custom_quality_pipeline\",\n",
    "    description=\"Pipeline with custom data quality checks\",\n",
    "    parameters={'algorithm': 'logistic_regression'}\n",
    ")\n",
    "\n",
    "custom_pipeline = SimplePipeline(custom_config)\n",
    "\n",
    "# Add standard steps\n",
    "custom_pipeline.add_step(PipelineStep(\n",
    "    name=\"data_loading\",\n",
    "    description=\"Load dataset\",\n",
    "    function=runner._data_loading_function\n",
    "))\n",
    "\n",
    "# Add custom quality check step\n",
    "custom_pipeline.add_step(PipelineStep(\n",
    "    name=\"data_quality_check\",\n",
    "    description=\"Perform custom data quality assessment\",\n",
    "    function=custom_data_quality_check\n",
    "))\n",
    "\n",
    "custom_pipeline.add_step(PipelineStep(\n",
    "    name=\"data_preprocessing\",\n",
    "    description=\"Preprocess data\",\n",
    "    function=runner._preprocessing_function\n",
    "))\n",
    "\n",
    "custom_pipeline.add_step(PipelineStep(\n",
    "    name=\"model_training\",\n",
    "    description=\"Train model\",\n",
    "    function=runner._training_function\n",
    "))\n",
    "\n",
    "print(f\"üõ†Ô∏è  Custom pipeline created with {len(custom_pipeline.steps)} steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df070094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute custom pipeline\n",
    "print(\"üöÄ Executing custom pipeline with quality checks...\")\n",
    "\n",
    "custom_result = custom_pipeline.execute()\n",
    "\n",
    "print(f\"\\n‚úÖ Custom pipeline completed: {custom_result.status}\")\n",
    "print(f\"üìä Results:\")\n",
    "print(f\"   - Steps: {custom_result.steps_completed}/{custom_result.steps_total}\")\n",
    "print(f\"   - Success rate: {custom_result.success_rate:.1%}\")\n",
    "print(f\"   - Duration: {custom_result.duration_seconds:.2f}s\")\n",
    "\n",
    "# Display quality metrics if available\n",
    "if 'quality_metrics' in custom_result.outputs:\n",
    "    quality_metrics = custom_result.outputs['quality_metrics']\n",
    "    quality_score = custom_result.outputs['quality_score']\n",
    "    \n",
    "    print(f\"\\nüìè Data Quality Assessment:\")\n",
    "    print(f\"   - Overall Quality Score: {quality_score:.1%}\")\n",
    "    print(f\"   - Null Percentage: {quality_metrics['null_percentage']:.2f}%\")\n",
    "    print(f\"   - Duplicate Percentage: {quality_metrics['duplicate_percentage']:.2f}%\")\n",
    "    print(f\"   - Data Completeness: {quality_metrics['data_completeness']:.2f}%\")\n",
    "    print(f\"   - Quality Check: {'‚úÖ PASSED' if custom_result.outputs['quality_passed'] else '‚ùå FAILED'}\")\n",
    "    \n",
    "    # Visualize quality metrics\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Quality metrics bar chart\n",
    "    metrics_names = list(quality_metrics.keys())\n",
    "    metrics_values = list(quality_metrics.values())\n",
    "    \n",
    "    bars = ax1.bar(metrics_names, metrics_values, \n",
    "                   color=['#e74c3c', '#f39c12', '#2ecc71'])\n",
    "    ax1.set_title('Data Quality Metrics', fontweight='bold')\n",
    "    ax1.set_ylabel('Percentage (%)')\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                f'{height:.1f}%', ha='center', va='bottom')\n",
    "    \n",
    "    # Quality score gauge\n",
    "    colors = ['#e74c3c', '#f39c12', '#2ecc71']\n",
    "    if quality_score < 0.6:\n",
    "        color = colors[0]  # Red\n",
    "    elif quality_score < 0.8:\n",
    "        color = colors[1]  # Yellow\n",
    "    else:\n",
    "        color = colors[2]  # Green\n",
    "    \n",
    "    ax2.pie([quality_score, 1-quality_score], \n",
    "           colors=[color, '#ecf0f1'],\n",
    "           startangle=90,\n",
    "           counterclock=False,\n",
    "           wedgeprops={'width': 0.3})\n",
    "    \n",
    "    ax2.text(0, 0, f'{quality_score:.1%}', \n",
    "            ha='center', va='center', fontsize=20, fontweight='bold')\n",
    "    ax2.set_title('Overall Quality Score', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe721e8c",
   "metadata": {},
   "source": [
    "## 8. Pipeline Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8dc764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"üéØ Pipeline Orchestration Summary\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "total_pipelines = len(runner.list_pipelines()) + 1  # +1 for custom pipeline\n",
    "successful_pipelines = sum(1 for name in runner.list_pipelines() \n",
    "                          if runner.get_pipeline_result(name) and \n",
    "                          runner.get_pipeline_result(name).status == 'completed')\n",
    "successful_pipelines += 1 if custom_result.status == 'completed' else 0\n",
    "\n",
    "print(f\"üìä Pipeline Execution Statistics:\")\n",
    "print(f\"   ‚Ä¢ Total pipelines executed: {total_pipelines}\")\n",
    "print(f\"   ‚Ä¢ Successful executions: {successful_pipelines}\")\n",
    "print(f\"   ‚Ä¢ Success rate: {(successful_pipelines/total_pipelines):.1%}\")\n",
    "\n",
    "print(f\"\\nüöÄ Pipeline Types Demonstrated:\")\n",
    "print(f\"   ‚úÖ Training Pipeline - Data ‚Üí Model\")\n",
    "print(f\"   ‚úÖ Deployment Pipeline - Model ‚Üí Production\")\n",
    "print(f\"   ‚úÖ Full MLOps Pipeline - End-to-end workflow\")\n",
    "print(f\"   ‚úÖ Custom Pipeline - Quality checks & validation\")\n",
    "\n",
    "print(f\"\\nüõ†Ô∏è  Features Demonstrated:\")\n",
    "print(f\"   ‚úÖ Simple local pipeline execution\")\n",
    "print(f\"   ‚úÖ Step-by-step progress tracking\")\n",
    "print(f\"   ‚úÖ Error handling and retries\")\n",
    "print(f\"   ‚úÖ Pipeline performance monitoring\")\n",
    "print(f\"   ‚úÖ Custom component integration\")\n",
    "print(f\"   ‚úÖ Data quality assessment\")\n",
    "print(f\"   ‚úÖ Comprehensive visualization\")\n",
    "\n",
    "print(f\"\\nüéØ Next Steps:\")\n",
    "print(f\"   1. Integrate with Vertex AI Pipelines for cloud execution\")\n",
    "print(f\"   2. Add pipeline scheduling and automation\")\n",
    "print(f\"   3. Implement pipeline versioning and rollback\")\n",
    "print(f\"   4. Add comprehensive monitoring and alerting\")\n",
    "print(f\"   5. Create reusable component library\")\n",
    "print(f\"   6. Implement CI/CD integration\")\n",
    "\n",
    "print(f\"\\n‚ú® Pipeline orchestration demonstration complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
