{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ee97189",
   "metadata": {},
   "source": [
    "# Vertex AI Pipelines - End-to-End MLOps Orchestration\n",
    "\n",
    "This notebook demonstrates comprehensive pipeline orchestration for MLOps workflows using both simple local execution and advanced Vertex AI Pipelines.\n",
    "\n",
    "## Features Covered\n",
    "- Simple local pipeline execution\n",
    "- Advanced Vertex AI Pipelines integration \n",
    "- End-to-end MLOps workflow orchestration\n",
    "- Pipeline monitoring and management\n",
    "- Component composition and reusability\n",
    "\n",
    "**Author:** MLOps Team  \n",
    "**Version:** 1.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b5fd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Google Cloud and Vertex AI Pipelines\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import storage\n",
    "import google.auth\n",
    "from kfp import dsl\n",
    "from kfp.v2 import compiler\n",
    "from kfp.v2.dsl import component, pipeline, Input, Output, Dataset, Model, Metrics\n",
    "\n",
    "print(\"üöÄ Setting up Vertex AI Pipelines Environment\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get Google Cloud configuration\n",
    "try:\n",
    "    # Get project ID from gcloud\n",
    "    result = subprocess.run(['gcloud', 'config', 'get-value', 'project'], \n",
    "                          capture_output=True, text=True)\n",
    "    if result.returncode == 0 and result.stdout.strip():\n",
    "        PROJECT_ID = result.stdout.strip()\n",
    "    else:\n",
    "        PROJECT_ID = \"mlops-295610\"  # fallback\n",
    "    \n",
    "    LOCATION = \"us-central1\"\n",
    "    PIPELINE_ROOT = f\"gs://{PROJECT_ID}-vertex-ai-staging/pipeline-artifacts\"\n",
    "    DATA_BUCKET = f\"{PROJECT_ID}-mlops-data-processing\" \n",
    "    MODELS_BUCKET = f\"{PROJECT_ID}-mlops-models\"\n",
    "    \n",
    "    print(f\"‚òÅÔ∏è Google Cloud Configuration:\")\n",
    "    print(f\"   üìã Project ID: {PROJECT_ID}\")\n",
    "    print(f\"   üåç Location: {LOCATION}\")\n",
    "    print(f\"   üîó Pipeline Root: {PIPELINE_ROOT}\")\n",
    "    print(f\"   ü™£ Data Bucket: {DATA_BUCKET}\")\n",
    "    print(f\"   ü§ñ Models Bucket: {MODELS_BUCKET}\")\n",
    "    \n",
    "    # Initialize Vertex AI\n",
    "    aiplatform.init(\n",
    "        project=PROJECT_ID, \n",
    "        location=LOCATION,\n",
    "        staging_bucket=f\"gs://{PROJECT_ID}-vertex-ai-staging\"\n",
    "    )\n",
    "    \n",
    "    # Initialize storage client\n",
    "    credentials, project = google.auth.default()\n",
    "    storage_client = storage.Client(project=PROJECT_ID)\n",
    "    \n",
    "    print(\"‚úÖ Vertex AI Pipelines initialized successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Setup error: {e}\")\n",
    "    print(\"   Using fallback configuration\")\n",
    "    \n",
    "    PROJECT_ID = \"mlops-295610\"\n",
    "    LOCATION = \"us-central1\"\n",
    "    PIPELINE_ROOT = f\"gs://{PROJECT_ID}-vertex-ai-staging/pipeline-artifacts\"\n",
    "\n",
    "print(f\"\\nüéØ Vertex AI Pipelines ready!\")\n",
    "print(f\"   \udcca Will orchestrate: Data Processing ‚Üí Training ‚Üí Deployment\")\n",
    "print(f\"   ‚òÅÔ∏è All artifacts stored in Google Cloud Storage\")\n",
    "print(f\"   üîÑ Fully managed execution on Vertex AI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f99b32",
   "metadata": {},
   "source": [
    "## 1. Pipeline Orchestration Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f57f859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pipeline orchestration modules\n",
    "from src.pipelines import (\n",
    "    SimplePipeline, LocalPipelineRunner, SimplePipelineConfig,\n",
    "    PipelineStep, PipelineResult, StepStatus, PipelineType,\n",
    "    create_pipeline_runner, run_sample_pipeline\n",
    ")\n",
    "\n",
    "from src.config import Config\n",
    "from src.utils import setup_logging\n",
    "\n",
    "# Initialize configuration\n",
    "config = Config()\n",
    "logger = setup_logging(__name__)\n",
    "\n",
    "print(\"üöÄ Pipeline orchestration modules imported\")\n",
    "print(f\"üìÅ Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b21613",
   "metadata": {},
   "source": [
    "## 2. Simple Local Pipeline Execution\n",
    "\n",
    "First, let's demonstrate simple local pipeline execution for development and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e641b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cloud-native pipeline components\n",
    "\n",
    "@component(\n",
    "    base_image=\"python:3.9-slim\",\n",
    "    packages_to_install=[\n",
    "        \"pandas==2.0.3\", \n",
    "        \"numpy==1.24.3\", \n",
    "        \"scikit-learn==1.3.0\",\n",
    "        \"google-cloud-storage==2.10.0\"\n",
    "    ]\n",
    ")\n",
    "def data_preprocessing_component(\n",
    "    project_id: str,\n",
    "    data_bucket: str,\n",
    "    processed_data: Output[Dataset],\n",
    "    preprocessing_metrics: Output[Metrics]\n",
    "):\n",
    "    \"\"\"Cloud-native data preprocessing component\"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "    from google.cloud import storage\n",
    "    import json\n",
    "    import pickle\n",
    "    import tempfile\n",
    "    import os\n",
    "    \n",
    "    print(f\"üîÑ Starting data preprocessing...\")\n",
    "    print(f\"   Project: {project_id}\")\n",
    "    print(f\"   Data bucket: {data_bucket}\")\n",
    "    \n",
    "    # Initialize storage client\n",
    "    storage_client = storage.Client(project=project_id)\n",
    "    bucket = storage_client.bucket(data_bucket)\n",
    "    \n",
    "    # Load raw data from GCS\n",
    "    print(\"üì• Loading raw data from GCS...\")\n",
    "    try:\n",
    "        blob = bucket.blob(\"raw-data/iris_dataset.csv\")\n",
    "        with tempfile.NamedTemporaryFile(mode='w+', suffix='.csv', delete=False) as tmp:\n",
    "            blob.download_to_filename(tmp.name)\n",
    "            df = pd.read_csv(tmp.name)\n",
    "            os.unlink(tmp.name)\n",
    "        \n",
    "        print(f\"‚úÖ Loaded dataset with shape: {df.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading data: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Preprocessing steps\n",
    "    print(\"üßπ Preprocessing data...\")\n",
    "    \n",
    "    # 1. Handle any missing values (though Iris shouldn't have any)\n",
    "    initial_rows = len(df)\n",
    "    df = df.dropna()\n",
    "    print(f\"   Removed {initial_rows - len(df)} rows with missing values\")\n",
    "    \n",
    "    # 2. Feature engineering - create feature combinations\n",
    "    if 'sepal_length' in df.columns and 'sepal_width' in df.columns:\n",
    "        df['sepal_area'] = df['sepal_length'] * df['sepal_width']\n",
    "        \n",
    "    if 'petal_length' in df.columns and 'petal_width' in df.columns:\n",
    "        df['petal_area'] = df['petal_length'] * df['petal_width']\n",
    "    \n",
    "    # 3. Prepare features and target\n",
    "    feature_cols = [col for col in df.columns if col != 'species']\n",
    "    X = df[feature_cols]\n",
    "    y = df['species']\n",
    "    \n",
    "    # 4. Encode target labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    \n",
    "    # 5. Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    "    )\n",
    "    \n",
    "    # 6. Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # 7. Combine processed data\n",
    "    train_df = pd.DataFrame(X_train_scaled, columns=feature_cols)\n",
    "    train_df['species'] = y_train\n",
    "    \n",
    "    test_df = pd.DataFrame(X_test_scaled, columns=feature_cols) \n",
    "    test_df['species'] = y_test\n",
    "    \n",
    "    print(f\"‚úÖ Preprocessing complete:\")\n",
    "    print(f\"   Training set: {train_df.shape}\")\n",
    "    print(f\"   Test set: {test_df.shape}\")\n",
    "    print(f\"   Features: {len(feature_cols)}\")\n",
    "    \n",
    "    # Save processed data to output path\n",
    "    print(\"üíæ Saving processed data...\")\n",
    "    \n",
    "    # Save training data\n",
    "    train_path = f\"{processed_data.path}/train.csv\"\n",
    "    os.makedirs(os.path.dirname(train_path), exist_ok=True)\n",
    "    train_df.to_csv(train_path, index=False)\n",
    "    \n",
    "    # Save test data\n",
    "    test_path = f\"{processed_data.path}/test.csv\"\n",
    "    test_df.to_csv(test_path, index=False)\n",
    "    \n",
    "    # Save preprocessing artifacts\n",
    "    metadata = {\n",
    "        'scaler': scaler,\n",
    "        'label_encoder': label_encoder,\n",
    "        'feature_columns': feature_cols,\n",
    "        'target_classes': label_encoder.classes_.tolist()\n",
    "    }\n",
    "    \n",
    "    metadata_path = f\"{processed_data.path}/metadata.pkl\"\n",
    "    with open(metadata_path, 'wb') as f:\n",
    "        pickle.dump(metadata, f)\n",
    "    \n",
    "    # Record preprocessing metrics\n",
    "    metrics = {\n",
    "        'original_rows': int(initial_rows),\n",
    "        'processed_rows': int(len(df)),\n",
    "        'training_samples': int(len(train_df)),\n",
    "        'test_samples': int(len(test_df)),\n",
    "        'feature_count': int(len(feature_cols)),\n",
    "        'target_classes': int(len(label_encoder.classes_))\n",
    "    }\n",
    "    \n",
    "    preprocessing_metrics.log_metric('original_rows', metrics['original_rows'])\n",
    "    preprocessing_metrics.log_metric('training_samples', metrics['training_samples'])\n",
    "    preprocessing_metrics.log_metric('test_samples', metrics['test_samples'])\n",
    "    preprocessing_metrics.log_metric('feature_count', metrics['feature_count'])\n",
    "    \n",
    "    print(\"‚úÖ Data preprocessing component completed successfully\")\n",
    "\n",
    "print(\"‚úÖ Data preprocessing component defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517f3bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"python:3.9-slim\",\n",
    "    packages_to_install=[\n",
    "        \"pandas==2.0.3\",\n",
    "        \"numpy==1.24.3\", \n",
    "        \"scikit-learn==1.3.0\",\n",
    "        \"google-cloud-storage==2.10.0\"\n",
    "    ]\n",
    ")\n",
    "def model_training_component(\n",
    "    project_id: str,\n",
    "    models_bucket: str,\n",
    "    processed_data: Input[Dataset],\n",
    "    trained_model: Output[Model],\n",
    "    training_metrics: Output[Metrics]\n",
    "):\n",
    "    \"\"\"Cloud-native model training component\"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    import json\n",
    "    from datetime import datetime\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.metrics import accuracy_score, classification_report\n",
    "    from google.cloud import storage\n",
    "    import tempfile\n",
    "    import os\n",
    "    \n",
    "    print(f\"ü§ñ Starting model training...\")\n",
    "    print(f\"   Project: {project_id}\")\n",
    "    print(f\"   Models bucket: {models_bucket}\")\n",
    "    \n",
    "    # Load processed data\n",
    "    print(\"üì• Loading processed training data...\")\n",
    "    \n",
    "    train_path = f\"{processed_data.path}/train.csv\"\n",
    "    test_path = f\"{processed_data.path}/test.csv\"\n",
    "    metadata_path = f\"{processed_data.path}/metadata.pkl\"\n",
    "    \n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    \n",
    "    with open(metadata_path, 'rb') as f:\n",
    "        metadata = pickle.load(f)\n",
    "    \n",
    "    feature_columns = metadata['feature_columns']\n",
    "    \n",
    "    # Prepare training data\n",
    "    X_train = train_df[feature_columns]\n",
    "    y_train = train_df['species']\n",
    "    X_test = test_df[feature_columns]\n",
    "    y_test = test_df['species']\n",
    "    \n",
    "    print(f\"‚úÖ Data loaded:\")\n",
    "    print(f\"   Training: {X_train.shape}\")\n",
    "    print(f\"   Test: {X_test.shape}\")\n",
    "    \n",
    "    # Define models to train\n",
    "    models = {\n",
    "        'random_forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        'logistic_regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "        'svm': SVC(random_state=42, probability=True),\n",
    "        'knn': KNeighborsClassifier(n_neighbors=3)\n",
    "    }\n",
    "    \n",
    "    print(f\"üèÉ Training {len(models)} models...\")\n",
    "    \n",
    "    # Train all models and track performance\n",
    "    training_results = {}\n",
    "    best_accuracy = 0\n",
    "    best_model = None\n",
    "    best_model_name = None\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        print(f\"   üîÑ Training {model_name}...\")\n",
    "        \n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate\n",
    "        train_pred = model.predict(X_train)\n",
    "        test_pred = model.predict(X_test)\n",
    "        \n",
    "        train_accuracy = accuracy_score(y_train, train_pred)\n",
    "        test_accuracy = accuracy_score(y_test, test_pred)\n",
    "        \n",
    "        training_time = (datetime.now() - start_time).total_seconds()\n",
    "        \n",
    "        # Store results\n",
    "        training_results[model_name] = {\n",
    "            'model': model,\n",
    "            'train_accuracy': train_accuracy,\n",
    "            'test_accuracy': test_accuracy,\n",
    "            'training_time': training_time\n",
    "        }\n",
    "        \n",
    "        print(f\"     ‚úÖ {model_name}: {test_accuracy:.4f} accuracy\")\n",
    "        \n",
    "        # Track best model\n",
    "        if test_accuracy > best_accuracy:\n",
    "            best_accuracy = test_accuracy\n",
    "            best_model = model\n",
    "            best_model_name = model_name\n",
    "    \n",
    "    print(f\"üèÜ Best model: {best_model_name} ({best_accuracy:.4f} accuracy)\")\n",
    "    \n",
    "    # Save best model to output path\n",
    "    print(\"üíæ Saving trained model...\")\n",
    "    \n",
    "    os.makedirs(trained_model.path, exist_ok=True)\n",
    "    \n",
    "    # Save the best model\n",
    "    model_path = f\"{trained_model.path}/model.pkl\"\n",
    "    with open(model_path, 'wb') as f:\n",
    "        pickle.dump(best_model, f)\n",
    "    \n",
    "    # Save model metadata\n",
    "    model_metadata = {\n",
    "        'model_name': best_model_name,\n",
    "        'model_type': type(best_model).__name__,\n",
    "        'accuracy': best_accuracy,\n",
    "        'training_timestamp': datetime.now().isoformat(),\n",
    "        'feature_columns': feature_columns,\n",
    "        'target_classes': metadata['target_classes'],\n",
    "        'all_results': {\n",
    "            name: {\n",
    "                'train_accuracy': float(results['train_accuracy']),\n",
    "                'test_accuracy': float(results['test_accuracy']),\n",
    "                'training_time': float(results['training_time'])\n",
    "            }\n",
    "            for name, results in training_results.items()\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    metadata_path = f\"{trained_model.path}/metadata.json\"\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(model_metadata, f, indent=2)\n",
    "    \n",
    "    # Upload to GCS for persistence\n",
    "    try:\n",
    "        print(\"‚òÅÔ∏è Uploading model to GCS...\")\n",
    "        storage_client = storage.Client(project=project_id)\n",
    "        bucket = storage_client.bucket(models_bucket)\n",
    "        \n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        \n",
    "        # Upload model file\n",
    "        blob = bucket.blob(f\"pipeline-models/model_{timestamp}.pkl\")\n",
    "        blob.upload_from_filename(model_path)\n",
    "        \n",
    "        # Upload metadata\n",
    "        metadata_blob = bucket.blob(f\"pipeline-models/metadata_{timestamp}.json\") \n",
    "        metadata_blob.upload_from_filename(metadata_path)\n",
    "        \n",
    "        print(f\"   ‚úÖ Model uploaded to gs://{models_bucket}/pipeline-models/\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è GCS upload error: {e}\")\n",
    "    \n",
    "    # Log training metrics\n",
    "    training_metrics.log_metric('best_accuracy', best_accuracy)\n",
    "    training_metrics.log_metric('models_trained', len(models))\n",
    "    training_metrics.log_metric('training_samples', len(X_train))\n",
    "    training_metrics.log_metric('test_samples', len(X_test))\n",
    "    \n",
    "    for name, results in training_results.items():\n",
    "        training_metrics.log_metric(f'{name}_accuracy', results['test_accuracy'])\n",
    "        training_metrics.log_metric(f'{name}_training_time', results['training_time'])\n",
    "    \n",
    "    # Set model URI for next component\n",
    "    trained_model.uri = f\"gs://{models_bucket}/pipeline-models/model_{timestamp}.pkl\"\n",
    "    \n",
    "    print(\"‚úÖ Model training component completed successfully\")\n",
    "\n",
    "print(\"‚úÖ Model training component defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3c77b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"python:3.9-slim\",\n",
    "    packages_to_install=[\n",
    "        \"google-cloud-aiplatform==1.35.0\",\n",
    "        \"google-cloud-storage==2.10.0\"\n",
    "    ]\n",
    ")\n",
    "def model_deployment_component(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    trained_model: Input[Model],\n",
    "    deployment_metrics: Output[Metrics]\n",
    "):\n",
    "    \"\"\"Cloud-native model deployment component using Vertex AI\"\"\"\n",
    "    import json\n",
    "    import tempfile\n",
    "    import os\n",
    "    from datetime import datetime\n",
    "    from google.cloud import aiplatform, storage\n",
    "    \n",
    "    print(f\"üöÄ Starting model deployment to Vertex AI...\")\n",
    "    print(f\"   Project: {project_id}\")\n",
    "    print(f\"   Location: {location}\")\n",
    "    print(f\"   Model URI: {trained_model.uri}\")\n",
    "    \n",
    "    # Initialize Vertex AI\n",
    "    aiplatform.init(project=project_id, location=location)\n",
    "    \n",
    "    try:\n",
    "        # Load model metadata\n",
    "        print(\"üìã Loading model metadata...\")\n",
    "        \n",
    "        # Extract bucket and path from model URI\n",
    "        model_uri_parts = trained_model.uri.replace('gs://', '').split('/', 1)\n",
    "        bucket_name = model_uri_parts[0]\n",
    "        object_path = model_uri_parts[1]\n",
    "        \n",
    "        # Get metadata path \n",
    "        metadata_path = object_path.replace('model_', 'metadata_').replace('.pkl', '.json')\n",
    "        \n",
    "        storage_client = storage.Client(project=project_id)\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        metadata_blob = bucket.blob(metadata_path)\n",
    "        \n",
    "        with tempfile.NamedTemporaryFile(mode='w+', suffix='.json', delete=False) as tmp:\n",
    "            metadata_blob.download_to_filename(tmp.name)\n",
    "            with open(tmp.name, 'r') as f:\n",
    "                model_metadata = json.load(f)\n",
    "            os.unlink(tmp.name)\n",
    "        \n",
    "        print(f\"   Model: {model_metadata['model_name']}\")\n",
    "        print(f\"   Accuracy: {model_metadata['accuracy']:.4f}\")\n",
    "        \n",
    "        # Create model display name with timestamp\n",
    "        timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "        model_display_name = f\"iris-classifier-{model_metadata['model_name']}-{timestamp}\"\n",
    "        endpoint_display_name = f\"iris-endpoint-{timestamp}\"\n",
    "        \n",
    "        print(f\"üì¶ Uploading model to Vertex AI Model Registry...\")\n",
    "        \n",
    "        # Upload model to Vertex AI\n",
    "        # For sklearn models, we need to create a custom serving container\n",
    "        # For demo purposes, we'll register the model metadata\n",
    "        \n",
    "        # Create a simple serving container specification\n",
    "        serving_container_spec = {\n",
    "            \"image_uri\": \"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-0:latest\",\n",
    "            \"predict_route\": \"/predict\",\n",
    "            \"health_route\": \"/health\"\n",
    "        }\n",
    "        \n",
    "        # Register model (this is a simplified approach)\n",
    "        # In production, you'd create a proper serving container with your model\n",
    "        model_resource = aiplatform.Model.upload(\n",
    "            display_name=model_display_name,\n",
    "            artifact_uri=os.path.dirname(trained_model.uri),\n",
    "            serving_container_image_uri=serving_container_spec[\"image_uri\"],\n",
    "            description=f\"Iris classifier using {model_metadata['model_name']} algorithm, accuracy: {model_metadata['accuracy']:.4f}\",\n",
    "        )\n",
    "        \n",
    "        print(f\"   ‚úÖ Model uploaded: {model_resource.display_name}\")\n",
    "        print(f\"   üìù Model ID: {model_resource.name}\")\n",
    "        \n",
    "        # Create endpoint\n",
    "        print(f\"üì° Creating Vertex AI endpoint...\")\n",
    "        \n",
    "        endpoint = aiplatform.Endpoint.create(\n",
    "            display_name=endpoint_display_name,\n",
    "            description=f\"Serving endpoint for iris classification model\"\n",
    "        )\n",
    "        \n",
    "        print(f\"   ‚úÖ Endpoint created: {endpoint.display_name}\")\n",
    "        print(f\"   üìù Endpoint ID: {endpoint.name}\")\n",
    "        \n",
    "        # Deploy model to endpoint\n",
    "        print(f\"üîÑ Deploying model to endpoint...\")\n",
    "        \n",
    "        endpoint.deploy(\n",
    "            model=model_resource,\n",
    "            deployed_model_display_name=f\"deployed-{model_display_name}\",\n",
    "            machine_type=\"n1-standard-2\",  # 2 vCPU, 7.5GB RAM\n",
    "            min_replica_count=1,\n",
    "            max_replica_count=3,\n",
    "            traffic_percentage=100\n",
    "        )\n",
    "        \n",
    "        print(f\"   ‚úÖ Model deployed successfully!\")\n",
    "        print(f\"   üîó Endpoint URL: {endpoint.gca_resource.name}\")\n",
    "        \n",
    "        # Log deployment metrics\n",
    "        deployment_metrics.log_metric('deployment_success', 1)\n",
    "        deployment_metrics.log_metric('model_accuracy', model_metadata['accuracy'])\n",
    "        deployment_metrics.log_metric('deployment_timestamp', datetime.now().timestamp())\n",
    "        \n",
    "        # Record deployment info\n",
    "        deployment_info = {\n",
    "            'model_id': model_resource.name,\n",
    "            'model_display_name': model_display_name,\n",
    "            'endpoint_id': endpoint.name, \n",
    "            'endpoint_display_name': endpoint_display_name,\n",
    "            'deployment_timestamp': datetime.now().isoformat(),\n",
    "            'model_accuracy': model_metadata['accuracy'],\n",
    "            'status': 'deployed'\n",
    "        }\n",
    "        \n",
    "        print(f\"üìä Deployment Summary:\")\n",
    "        for key, value in deployment_info.items():\n",
    "            print(f\"   {key}: {value}\")\n",
    "        \n",
    "        print(\"‚úÖ Model deployment component completed successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Deployment error: {e}\")\n",
    "        print(\"   This is normal in a development environment\")\n",
    "        print(\"   In production, ensure proper model serving containers are created\")\n",
    "        \n",
    "        # Log failure metrics\n",
    "        deployment_metrics.log_metric('deployment_success', 0)\n",
    "        deployment_metrics.log_metric('error_occurred', 1)\n",
    "        \n",
    "        # For demo purposes, create a mock successful deployment\n",
    "        print(f\"üìä Mock Deployment (for demo):\")\n",
    "        print(f\"   Model would be deployed to Vertex AI endpoint\")\n",
    "        print(f\"   Ready to serve predictions via REST API\")\n",
    "        print(f\"   Monitoring and logging enabled\")\n",
    "\n",
    "print(\"‚úÖ Model deployment component defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be34be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display pipeline metrics\n",
    "if result.metrics:\n",
    "    print(\"üìà Model Performance Metrics:\")\n",
    "    for metric_name, value in result.metrics.items():\n",
    "        print(f\"   - {metric_name.title()}: {value:.4f}\")\n",
    "    \n",
    "    # Create metrics visualization\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    metrics_df = pd.DataFrame([\n",
    "        {'Metric': k.title(), 'Value': v} \n",
    "        for k, v in result.metrics.items()\n",
    "    ])\n",
    "    \n",
    "    bars = ax.bar(metrics_df['Metric'], metrics_df['Value'], \n",
    "                  color=['#3498db', '#e74c3c', '#2ecc71', '#f39c12'])\n",
    "    \n",
    "    ax.set_title('Model Performance Metrics', fontsize=16, fontweight='bold')\n",
    "    ax.set_ylabel('Score', fontsize=12)\n",
    "    ax.set_ylim(0, 1)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                f'{height:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  No metrics available in pipeline result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0838c9",
   "metadata": {},
   "source": [
    "## 3. Deployment Pipeline\n",
    "\n",
    "Now let's create and execute a deployment pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e95301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the complete MLOps pipeline\n",
    "@pipeline(\n",
    "    name=\"iris-mlops-pipeline\",\n",
    "    description=\"Complete MLOps pipeline for Iris classification: data processing, training, and deployment\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    ")\n",
    "def iris_mlops_pipeline(\n",
    "    project_id: str = PROJECT_ID,\n",
    "    location: str = LOCATION,\n",
    "    data_bucket: str = f\"{PROJECT_ID}-mlops-data-processing\",\n",
    "    models_bucket: str = f\"{PROJECT_ID}-mlops-models\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Complete MLOps pipeline that orchestrates:\n",
    "    1. Data preprocessing and feature engineering\n",
    "    2. Model training with multiple algorithms  \n",
    "    3. Model deployment to Vertex AI endpoint\n",
    "    \n",
    "    All steps run on Google Cloud with full artifact tracking.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Data Preprocessing\n",
    "    data_preprocessing_task = data_preprocessing_component(\n",
    "        project_id=project_id,\n",
    "        data_bucket=data_bucket\n",
    "    )\n",
    "    data_preprocessing_task.set_display_name(\"Data Processing\")\n",
    "    data_preprocessing_task.set_memory_limit(\"2Gi\")\n",
    "    data_preprocessing_task.set_cpu_limit(\"1\")\n",
    "    \n",
    "    # Step 2: Model Training  \n",
    "    model_training_task = model_training_component(\n",
    "        project_id=project_id,\n",
    "        models_bucket=models_bucket,\n",
    "        processed_data=data_preprocessing_task.outputs[\"processed_data\"]\n",
    "    )\n",
    "    model_training_task.set_display_name(\"Model Training\")\n",
    "    model_training_task.set_memory_limit(\"4Gi\") \n",
    "    model_training_task.set_cpu_limit(\"2\")\n",
    "    model_training_task.after(data_preprocessing_task)\n",
    "    \n",
    "    # Step 3: Model Deployment\n",
    "    model_deployment_task = model_deployment_component(\n",
    "        project_id=project_id,\n",
    "        location=location,\n",
    "        trained_model=model_training_task.outputs[\"trained_model\"]\n",
    "    )\n",
    "    model_deployment_task.set_display_name(\"Model Deployment\")\n",
    "    model_deployment_task.set_memory_limit(\"2Gi\")\n",
    "    model_deployment_task.set_cpu_limit(\"1\") \n",
    "    model_deployment_task.after(model_training_task)\n",
    "\n",
    "print(\"‚úÖ Complete MLOps pipeline defined!\")\n",
    "print(f\"üìä Pipeline includes:\")\n",
    "print(f\"   1. üßπ Data Preprocessing - Feature engineering & data splits\")\n",
    "print(f\"   2. ü§ñ Model Training - Multi-algorithm training & selection\")\n",
    "print(f\"   3. üöÄ Model Deployment - Vertex AI endpoint deployment\")\n",
    "print(f\"   4. üìà Metrics Tracking - Performance monitoring throughout\")\n",
    "print(f\"   5. ‚òÅÔ∏è Cloud Storage - All artifacts stored in GCS\")\n",
    "\n",
    "# Compile the pipeline\n",
    "print(f\"\\nüì¶ Compiling pipeline...\")\n",
    "\n",
    "pipeline_file = \"iris_mlops_pipeline.json\"\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=iris_mlops_pipeline,\n",
    "    package_path=pipeline_file\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Pipeline compiled to: {pipeline_file}\")\n",
    "print(f\"üéØ Ready to run on Vertex AI Pipelines!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7e8021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute deployment pipeline\n",
    "print(\"üöÄ Starting deployment pipeline...\")\n",
    "\n",
    "deployment_result = runner.run_pipeline(deployment_config.name)\n",
    "\n",
    "print(f\"\\n‚úÖ Deployment pipeline completed!\")\n",
    "print(f\"üìä Results:\")\n",
    "print(f\"   - Status: {deployment_result.status}\")\n",
    "print(f\"   - Steps completed: {deployment_result.steps_completed}/{deployment_result.steps_total}\")\n",
    "print(f\"   - Success rate: {deployment_result.success_rate:.1%}\")\n",
    "print(f\"   - Duration: {deployment_result.duration_seconds:.2f}s\")\n",
    "\n",
    "if deployment_result.outputs:\n",
    "    print(f\"\\nüîó Deployment Outputs:\")\n",
    "    for key, value in deployment_result.outputs.items():\n",
    "        if isinstance(value, str) and len(value) < 100:\n",
    "            print(f\"   - {key}: {value}\")\n",
    "        else:\n",
    "            print(f\"   - {key}: <{type(value).__name__}>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6566ff5d",
   "metadata": {},
   "source": [
    "## 4. Full End-to-End MLOps Pipeline\n",
    "\n",
    "Let's create and execute a complete end-to-end MLOps pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390b680a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the pipeline on Vertex AI Pipelines\n",
    "print(\"üöÄ Executing MLOps Pipeline on Vertex AI\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create a unique pipeline job name\n",
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "job_id = f\"iris-mlops-pipeline-{timestamp}\"\n",
    "\n",
    "print(f\"üìã Pipeline Execution Details:\")\n",
    "print(f\"   Job ID: {job_id}\")\n",
    "print(f\"   Pipeline File: {pipeline_file}\")\n",
    "print(f\"   Project: {PROJECT_ID}\")\n",
    "print(f\"   Location: {LOCATION}\")\n",
    "print(f\"   Pipeline Root: {PIPELINE_ROOT}\")\n",
    "\n",
    "try:\n",
    "    # Submit the pipeline job\n",
    "    print(f\"\\nüîÑ Submitting pipeline job to Vertex AI...\")\n",
    "    \n",
    "    pipeline_job = aiplatform.PipelineJob(\n",
    "        display_name=job_id,\n",
    "        template_path=pipeline_file,\n",
    "        pipeline_root=PIPELINE_ROOT,\n",
    "        parameter_values={\n",
    "            \"project_id\": PROJECT_ID,\n",
    "            \"location\": LOCATION,\n",
    "            \"data_bucket\": f\"{PROJECT_ID}-mlops-data-processing\",\n",
    "            \"models_bucket\": f\"{PROJECT_ID}-mlops-models\"\n",
    "        },\n",
    "        enable_caching=True\n",
    "    )\n",
    "    \n",
    "    # Run the pipeline\n",
    "    pipeline_job.submit()\n",
    "    \n",
    "    print(f\"‚úÖ Pipeline job submitted successfully!\")\n",
    "    print(f\"üìä Job Details:\")\n",
    "    print(f\"   Name: {pipeline_job.display_name}\")\n",
    "    print(f\"   Resource Name: {pipeline_job.resource_name}\")\n",
    "    print(f\"   State: {pipeline_job.state}\")\n",
    "    \n",
    "    # Provide monitoring information\n",
    "    print(f\"\\nüìà Monitoring Your Pipeline:\")\n",
    "    print(f\"   üåê Console: https://console.cloud.google.com/vertex-ai/pipelines/runs?project={PROJECT_ID}\")\n",
    "    print(f\"   üì± Mobile: Google Cloud Console app\")\n",
    "    \n",
    "    print(f\"\\n‚è±Ô∏è  Pipeline Execution Timeline (estimated):\")\n",
    "    print(f\"   üìä Data Processing: 2-3 minutes\")\n",
    "    print(f\"   ü§ñ Model Training: 3-5 minutes\")  \n",
    "    print(f\"   üöÄ Model Deployment: 5-8 minutes\")\n",
    "    print(f\"   üìã Total Time: 10-16 minutes\")\n",
    "    \n",
    "    print(f\"\\nüéØ What's happening:\")\n",
    "    print(f\"   1. üßπ Loading & preprocessing Iris data in cloud\")\n",
    "    print(f\"   2. ü§ñ Training 4 ML models (RF, LR, SVM, KNN)\")\n",
    "    print(f\"   3. \udfc6 Selecting best performing model\")\n",
    "    print(f\"   4. üöÄ Deploying to Vertex AI endpoint\")\n",
    "    print(f\"   5. ‚úÖ Ready to serve predictions!\")\n",
    "    \n",
    "    # Store job info for later monitoring\n",
    "    pipeline_job_info = {\n",
    "        'job_id': job_id,\n",
    "        'resource_name': pipeline_job.resource_name,\n",
    "        'submission_time': datetime.now().isoformat(),\n",
    "        'project_id': PROJECT_ID,\n",
    "        'location': LOCATION,\n",
    "        'status': 'SUBMITTED'\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n‚úÖ Your complete MLOps pipeline is now running on Google Cloud!\")\n",
    "    print(f\"üîÑ Check the Vertex AI console for real-time progress\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Pipeline submission error: {e}\")\n",
    "    print(f\"\\nüîß Possible issues:\")\n",
    "    print(f\"   ‚Ä¢ Vertex AI Pipelines API not enabled\")\n",
    "    print(f\"   ‚Ä¢ Insufficient permissions\")\n",
    "    print(f\"   ‚Ä¢ Network connectivity issues\")\n",
    "    print(f\"   ‚Ä¢ Bucket access problems\")\n",
    "    \n",
    "    print(f\"\\nüõ†Ô∏è  To fix:\")\n",
    "    print(f\"   1. Enable APIs: gcloud services enable aiplatform.googleapis.com\")\n",
    "    print(f\"   2. Check permissions: gcloud auth list\")\n",
    "    print(f\"   3. Verify project: gcloud config get-value project\")\n",
    "    \n",
    "    # For demo purposes, show what would happen\n",
    "    print(f\"\\nüìä Demo: Pipeline Would Execute These Steps:\")\n",
    "    print(f\"   ‚úÖ Data preprocessing component\")\n",
    "    print(f\"   ‚úÖ Multi-model training component\") \n",
    "    print(f\"   ‚úÖ Model deployment component\")\n",
    "    print(f\"   ‚úÖ Full artifact tracking in GCS\")\n",
    "\n",
    "print(f\"\\nüéâ MLOps Pipeline Setup Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee131330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute full MLOps pipeline with progress tracking\n",
    "print(\"üöÄ Starting full MLOps pipeline...\")\n",
    "print(\"üìä Progress will be tracked step by step\\n\")\n",
    "\n",
    "# Execute pipeline\n",
    "mlops_result = runner.run_pipeline(mlops_config.name)\n",
    "\n",
    "print(f\"\\nüéâ Full MLOps pipeline completed!\")\n",
    "print(f\"üìä Final Results:\")\n",
    "print(f\"   - Overall Status: {mlops_result.status.upper()}\")\n",
    "print(f\"   - Steps completed: {mlops_result.steps_completed}/{mlops_result.steps_total}\")\n",
    "print(f\"   - Success rate: {mlops_result.success_rate:.1%}\")\n",
    "print(f\"   - Total duration: {mlops_result.duration_seconds:.2f}s\")\n",
    "print(f\"   - Start time: {mlops_result.start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"   - End time: {mlops_result.end_time.strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad66ab47",
   "metadata": {},
   "source": [
    "## 5. Pipeline Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fb3fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze pipeline performance\n",
    "pipeline_results = {\n",
    "    'Training Pipeline': result,\n",
    "    'Deployment Pipeline': deployment_result,\n",
    "    'Full MLOps Pipeline': mlops_result\n",
    "}\n",
    "\n",
    "# Create performance comparison\n",
    "performance_data = []\n",
    "for name, res in pipeline_results.items():\n",
    "    performance_data.append({\n",
    "        'Pipeline': name,\n",
    "        'Status': res.status,\n",
    "        'Steps Completed': res.steps_completed,\n",
    "        'Total Steps': res.steps_total,\n",
    "        'Success Rate': res.success_rate,\n",
    "        'Duration (s)': res.duration_seconds\n",
    "    })\n",
    "\n",
    "performance_df = pd.DataFrame(performance_data)\n",
    "print(\"üìä Pipeline Performance Comparison:\")\n",
    "print(performance_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8941cfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize pipeline performance\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Success rate comparison\n",
    "axes[0,0].bar(performance_df['Pipeline'], performance_df['Success Rate'], \n",
    "              color=['#3498db', '#e74c3c', '#2ecc71'])\n",
    "axes[0,0].set_title('Pipeline Success Rates', fontweight='bold')\n",
    "axes[0,0].set_ylabel('Success Rate')\n",
    "axes[0,0].set_ylim(0, 1.1)\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Duration comparison\n",
    "axes[0,1].bar(performance_df['Pipeline'], performance_df['Duration (s)'], \n",
    "              color=['#f39c12', '#9b59b6', '#1abc9c'])\n",
    "axes[0,1].set_title('Pipeline Execution Duration', fontweight='bold')\n",
    "axes[0,1].set_ylabel('Duration (seconds)')\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Steps completion\n",
    "x = range(len(performance_df))\n",
    "width = 0.35\n",
    "axes[1,0].bar([i - width/2 for i in x], performance_df['Steps Completed'], width, \n",
    "              label='Completed', color='#2ecc71')\n",
    "axes[1,0].bar([i + width/2 for i in x], performance_df['Total Steps'], width, \n",
    "              label='Total', color='#34495e')\n",
    "axes[1,0].set_title('Pipeline Steps Completion', fontweight='bold')\n",
    "axes[1,0].set_ylabel('Number of Steps')\n",
    "axes[1,0].set_xticks(x)\n",
    "axes[1,0].set_xticklabels(performance_df['Pipeline'], rotation=45)\n",
    "axes[1,0].legend()\n",
    "\n",
    "# Pipeline status pie chart\n",
    "status_counts = performance_df['Status'].value_counts()\n",
    "colors = ['#2ecc71' if status == 'completed' else '#e74c3c' for status in status_counts.index]\n",
    "axes[1,1].pie(status_counts.values, labels=status_counts.index, autopct='%1.1f%%',\n",
    "              colors=colors, startangle=90)\n",
    "axes[1,1].set_title('Pipeline Status Distribution', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481d067b",
   "metadata": {},
   "source": [
    "## 6. Pipeline Management and Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e1f15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all pipelines and their results\n",
    "all_pipelines = runner.list_pipelines()\n",
    "print(f\"üìã Registered Pipelines ({len(all_pipelines)}):\")\n",
    "\n",
    "for i, pipeline_name in enumerate(all_pipelines, 1):\n",
    "    result = runner.get_pipeline_result(pipeline_name)\n",
    "    if result:\n",
    "        print(f\"   {i}. {pipeline_name}\")\n",
    "        print(f\"      - Status: {result.status}\")\n",
    "        print(f\"      - Duration: {result.duration_seconds:.2f}s\")\n",
    "        print(f\"      - Success Rate: {result.success_rate:.1%}\")\n",
    "        if result.error_message:\n",
    "            print(f\"      - Error: {result.error_message[:100]}...\")\n",
    "    else:\n",
    "        print(f\"   {i}. {pipeline_name} (No results available)\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d6cc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline step analysis\n",
    "if len(mlops_pipeline.steps) > 0:\n",
    "    print(\"üîç Detailed Step Analysis (Full MLOps Pipeline):\")\n",
    "    \n",
    "    step_analysis = []\n",
    "    for i, step in enumerate(mlops_pipeline.steps, 1):\n",
    "        duration = 0\n",
    "        if step.start_time and step.end_time:\n",
    "            duration = (step.end_time - step.start_time).total_seconds()\n",
    "        \n",
    "        step_analysis.append({\n",
    "            'Step': f\"{i}. {step.name}\",\n",
    "            'Status': step.status.value,\n",
    "            'Duration (s)': f\"{duration:.2f}\",\n",
    "            'Retries': step.retry_count,\n",
    "            'Description': step.description[:50] + '...' if len(step.description) > 50 else step.description\n",
    "        })\n",
    "    \n",
    "    step_df = pd.DataFrame(step_analysis)\n",
    "    print(step_df.to_string(index=False))\n",
    "    \n",
    "    # Step status visualization\n",
    "    status_colors = {\n",
    "        'completed': '#2ecc71',\n",
    "        'failed': '#e74c3c',\n",
    "        'pending': '#f39c12',\n",
    "        'running': '#3498db',\n",
    "        'skipped': '#95a5a6'\n",
    "    }\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    step_statuses = [step.status.value for step in mlops_pipeline.steps]\n",
    "    colors = [status_colors.get(status, '#34495e') for status in step_statuses]\n",
    "    \n",
    "    bars = ax.bar(range(len(step_statuses)), [1] * len(step_statuses), color=colors)\n",
    "    ax.set_title('Pipeline Step Status Overview', fontsize=16, fontweight='bold')\n",
    "    ax.set_xlabel('Pipeline Steps')\n",
    "    ax.set_ylabel('Status')\n",
    "    ax.set_xticks(range(len(mlops_pipeline.steps)))\n",
    "    ax.set_xticklabels([f\"{i+1}. {step.name}\" for i, step in enumerate(mlops_pipeline.steps)], \n",
    "                       rotation=45, ha='right')\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    # Add legend\n",
    "    unique_statuses = list(set(step_statuses))\n",
    "    legend_elements = [plt.Rectangle((0,0),1,1, facecolor=status_colors.get(status, '#34495e'), \n",
    "                                   label=status.title()) for status in unique_statuses]\n",
    "    ax.legend(handles=legend_elements, loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b176e73",
   "metadata": {},
   "source": [
    "## 7. Advanced Pipeline Features\n",
    "\n",
    "Demonstrate advanced pipeline features and integrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef7ab11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom pipeline step example\n",
    "def custom_data_quality_check(**kwargs):\n",
    "    \"\"\"Custom data quality check step.\"\"\"\n",
    "    logger.info(\"Executing custom data quality check\")\n",
    "    \n",
    "    data = kwargs.get('data', kwargs.get('processed_data'))\n",
    "    if data is None:\n",
    "        raise ValueError(\"No data provided for quality check\")\n",
    "    \n",
    "    # Perform quality checks\n",
    "    quality_metrics = {\n",
    "        'null_percentage': (data.isnull().sum().sum() / (len(data) * len(data.columns))) * 100,\n",
    "        'duplicate_percentage': (data.duplicated().sum() / len(data)) * 100,\n",
    "        'data_completeness': ((len(data) * len(data.columns) - data.isnull().sum().sum()) / \n",
    "                             (len(data) * len(data.columns))) * 100\n",
    "    }\n",
    "    \n",
    "    # Quality score\n",
    "    quality_score = (\n",
    "        (100 - quality_metrics['null_percentage']) * 0.4 +\n",
    "        (100 - quality_metrics['duplicate_percentage']) * 0.3 +\n",
    "        quality_metrics['data_completeness'] * 0.3\n",
    "    ) / 100\n",
    "    \n",
    "    quality_passed = quality_score > 0.8  # 80% threshold\n",
    "    \n",
    "    return {\n",
    "        'quality_metrics': quality_metrics,\n",
    "        'quality_score': quality_score,\n",
    "        'quality_passed': quality_passed,\n",
    "        'data': data  # Pass through data\n",
    "    }\n",
    "\n",
    "# Create custom pipeline with quality check\n",
    "custom_config = SimplePipelineConfig(\n",
    "    name=\"custom_quality_pipeline\",\n",
    "    description=\"Pipeline with custom data quality checks\",\n",
    "    parameters={'algorithm': 'logistic_regression'}\n",
    ")\n",
    "\n",
    "custom_pipeline = SimplePipeline(custom_config)\n",
    "\n",
    "# Add standard steps\n",
    "custom_pipeline.add_step(PipelineStep(\n",
    "    name=\"data_loading\",\n",
    "    description=\"Load dataset\",\n",
    "    function=runner._data_loading_function\n",
    "))\n",
    "\n",
    "# Add custom quality check step\n",
    "custom_pipeline.add_step(PipelineStep(\n",
    "    name=\"data_quality_check\",\n",
    "    description=\"Perform custom data quality assessment\",\n",
    "    function=custom_data_quality_check\n",
    "))\n",
    "\n",
    "custom_pipeline.add_step(PipelineStep(\n",
    "    name=\"data_preprocessing\",\n",
    "    description=\"Preprocess data\",\n",
    "    function=runner._preprocessing_function\n",
    "))\n",
    "\n",
    "custom_pipeline.add_step(PipelineStep(\n",
    "    name=\"model_training\",\n",
    "    description=\"Train model\",\n",
    "    function=runner._training_function\n",
    "))\n",
    "\n",
    "print(f\"üõ†Ô∏è  Custom pipeline created with {len(custom_pipeline.steps)} steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df070094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute custom pipeline\n",
    "print(\"üöÄ Executing custom pipeline with quality checks...\")\n",
    "\n",
    "custom_result = custom_pipeline.execute()\n",
    "\n",
    "print(f\"\\n‚úÖ Custom pipeline completed: {custom_result.status}\")\n",
    "print(f\"üìä Results:\")\n",
    "print(f\"   - Steps: {custom_result.steps_completed}/{custom_result.steps_total}\")\n",
    "print(f\"   - Success rate: {custom_result.success_rate:.1%}\")\n",
    "print(f\"   - Duration: {custom_result.duration_seconds:.2f}s\")\n",
    "\n",
    "# Display quality metrics if available\n",
    "if 'quality_metrics' in custom_result.outputs:\n",
    "    quality_metrics = custom_result.outputs['quality_metrics']\n",
    "    quality_score = custom_result.outputs['quality_score']\n",
    "    \n",
    "    print(f\"\\nüìè Data Quality Assessment:\")\n",
    "    print(f\"   - Overall Quality Score: {quality_score:.1%}\")\n",
    "    print(f\"   - Null Percentage: {quality_metrics['null_percentage']:.2f}%\")\n",
    "    print(f\"   - Duplicate Percentage: {quality_metrics['duplicate_percentage']:.2f}%\")\n",
    "    print(f\"   - Data Completeness: {quality_metrics['data_completeness']:.2f}%\")\n",
    "    print(f\"   - Quality Check: {'‚úÖ PASSED' if custom_result.outputs['quality_passed'] else '‚ùå FAILED'}\")\n",
    "    \n",
    "    # Visualize quality metrics\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Quality metrics bar chart\n",
    "    metrics_names = list(quality_metrics.keys())\n",
    "    metrics_values = list(quality_metrics.values())\n",
    "    \n",
    "    bars = ax1.bar(metrics_names, metrics_values, \n",
    "                   color=['#e74c3c', '#f39c12', '#2ecc71'])\n",
    "    ax1.set_title('Data Quality Metrics', fontweight='bold')\n",
    "    ax1.set_ylabel('Percentage (%)')\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                f'{height:.1f}%', ha='center', va='bottom')\n",
    "    \n",
    "    # Quality score gauge\n",
    "    colors = ['#e74c3c', '#f39c12', '#2ecc71']\n",
    "    if quality_score < 0.6:\n",
    "        color = colors[0]  # Red\n",
    "    elif quality_score < 0.8:\n",
    "        color = colors[1]  # Yellow\n",
    "    else:\n",
    "        color = colors[2]  # Green\n",
    "    \n",
    "    ax2.pie([quality_score, 1-quality_score], \n",
    "           colors=[color, '#ecf0f1'],\n",
    "           startangle=90,\n",
    "           counterclock=False,\n",
    "           wedgeprops={'width': 0.3})\n",
    "    \n",
    "    ax2.text(0, 0, f'{quality_score:.1%}', \n",
    "            ha='center', va='center', fontsize=20, fontweight='bold')\n",
    "    ax2.set_title('Overall Quality Score', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe721e8c",
   "metadata": {},
   "source": [
    "## 8. Pipeline Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8dc764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"üéØ Pipeline Orchestration Summary\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "total_pipelines = len(runner.list_pipelines()) + 1  # +1 for custom pipeline\n",
    "successful_pipelines = sum(1 for name in runner.list_pipelines() \n",
    "                          if runner.get_pipeline_result(name) and \n",
    "                          runner.get_pipeline_result(name).status == 'completed')\n",
    "successful_pipelines += 1 if custom_result.status == 'completed' else 0\n",
    "\n",
    "print(f\"üìä Pipeline Execution Statistics:\")\n",
    "print(f\"   ‚Ä¢ Total pipelines executed: {total_pipelines}\")\n",
    "print(f\"   ‚Ä¢ Successful executions: {successful_pipelines}\")\n",
    "print(f\"   ‚Ä¢ Success rate: {(successful_pipelines/total_pipelines):.1%}\")\n",
    "\n",
    "print(f\"\\nüöÄ Pipeline Types Demonstrated:\")\n",
    "print(f\"   ‚úÖ Training Pipeline - Data ‚Üí Model\")\n",
    "print(f\"   ‚úÖ Deployment Pipeline - Model ‚Üí Production\")\n",
    "print(f\"   ‚úÖ Full MLOps Pipeline - End-to-end workflow\")\n",
    "print(f\"   ‚úÖ Custom Pipeline - Quality checks & validation\")\n",
    "\n",
    "print(f\"\\nüõ†Ô∏è  Features Demonstrated:\")\n",
    "print(f\"   ‚úÖ Simple local pipeline execution\")\n",
    "print(f\"   ‚úÖ Step-by-step progress tracking\")\n",
    "print(f\"   ‚úÖ Error handling and retries\")\n",
    "print(f\"   ‚úÖ Pipeline performance monitoring\")\n",
    "print(f\"   ‚úÖ Custom component integration\")\n",
    "print(f\"   ‚úÖ Data quality assessment\")\n",
    "print(f\"   ‚úÖ Comprehensive visualization\")\n",
    "\n",
    "print(f\"\\nüéØ Next Steps:\")\n",
    "print(f\"   1. Integrate with Vertex AI Pipelines for cloud execution\")\n",
    "print(f\"   2. Add pipeline scheduling and automation\")\n",
    "print(f\"   3. Implement pipeline versioning and rollback\")\n",
    "print(f\"   4. Add comprehensive monitoring and alerting\")\n",
    "print(f\"   5. Create reusable component library\")\n",
    "print(f\"   6. Implement CI/CD integration\")\n",
    "\n",
    "print(f\"\\n‚ú® Pipeline orchestration demonstration complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
