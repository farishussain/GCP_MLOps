{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c66bf022",
   "metadata": {},
   "source": [
    "# Vertex AI Training Pipeline\n",
    "\n",
    "This notebook demonstrates cloud-based model training using Google Cloud Vertex AI, including:\n",
    "- Setting up Google Cloud authentication and configuration\n",
    "- Uploading training data to Google Cloud Storage\n",
    "- Creating custom training jobs on Vertex AI\n",
    "- Monitoring training progress and retrieving results\n",
    "- Hyperparameter tuning with Vertex AI\n",
    "- Model deployment to Vertex AI endpoints\n",
    "- Best practices for production MLOps workflows\n",
    "\n",
    "**Author:** MLOps Team  \n",
    "**Version:** 1.0.0  \n",
    "**Date:** November 2024  \n",
    "**Phase:** 4 - Cloud Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f745d50d",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration\n",
    "\n",
    "Import necessary libraries and configure the cloud training environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84843b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import subprocess\n",
    "import time\n",
    "import yaml\n",
    "\n",
    "# Add src to path for imports\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import our custom modules\n",
    "from config import Config\n",
    "from utils import setup_logging\n",
    "from cloud.vertex_ai import VertexAITrainer, TrainingJobConfig, CloudTrainingUtils\n",
    "from models.trainer import ModelTrainer\n",
    "from data.data_loader import DataLoader\n",
    "\n",
    "# Configure warnings and display\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")\n",
    "print(f\"üìÖ Notebook started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"üå•Ô∏è  Vertex AI Training Pipeline - Phase 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ec454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config = Config('../configs/config.yaml')\n",
    "\n",
    "# Setup logging\n",
    "logger = setup_logging('vertex_ai_training', level='INFO')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_STATE = config.project.random_state\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Define paths\n",
    "DATA_DIR = Path(config.paths.data_dir)\n",
    "PROCESSED_DATA_DIR = DATA_DIR / \"processed\"\n",
    "MODELS_DIR = Path(\"../models\")\n",
    "CLOUD_DIR = Path(\"../cloud_artifacts\")\n",
    "CLOUD_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"üîß Configuration loaded from: {config.config_path}\")\n",
    "print(f\"üé≤ Random state: {RANDOM_STATE}\")\n",
    "print(f\"üìÇ Data directory: {PROCESSED_DATA_DIR}\")\n",
    "print(f\"üíæ Models directory: {MODELS_DIR}\")\n",
    "print(f\"‚òÅÔ∏è  Cloud artifacts: {CLOUD_DIR}\")\n",
    "\n",
    "logger.info(\"Vertex AI training environment configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac4feaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Cloud Configuration\n",
    "# Note: Update these values for your specific Google Cloud project\n",
    "PROJECT_ID = \"your-gcp-project-id\"  # Replace with your actual project ID\n",
    "LOCATION = \"us-central1\"  # Vertex AI region\n",
    "STAGING_BUCKET = f\"{PROJECT_ID}-vertex-ai\"  # GCS bucket for staging\n",
    "\n",
    "print(\"üå•Ô∏è  Google Cloud Configuration:\")\n",
    "print(f\"   üìã Project ID: {PROJECT_ID}\")\n",
    "print(f\"   üåç Location: {LOCATION}\")\n",
    "print(f\"   üóÇÔ∏è  Staging Bucket: gs://{STAGING_BUCKET}\")\n",
    "\n",
    "# Check Google Cloud CLI availability\n",
    "def check_gcloud_auth():\n",
    "    \"\"\"Check if gcloud CLI is installed and authenticated.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(['gcloud', 'auth', 'list', '--format=json'], \n",
    "                              capture_output=True, text=True, timeout=10)\n",
    "        if result.returncode == 0:\n",
    "            accounts = json.loads(result.stdout)\n",
    "            active_account = [acc for acc in accounts if acc.get('status') == 'ACTIVE']\n",
    "            if active_account:\n",
    "                print(f\"‚úÖ Authenticated with Google Cloud as: {active_account[0]['account']}\")\n",
    "                return True\n",
    "            else:\n",
    "                print(\"‚ùå No active Google Cloud authentication found\")\n",
    "                return False\n",
    "        else:\n",
    "            print(\"‚ùå Google Cloud CLI not properly configured\")\n",
    "            return False\n",
    "    except (subprocess.TimeoutExpired, FileNotFoundError, json.JSONDecodeError):\n",
    "        print(\"‚ùå Google Cloud CLI not found or authentication failed\")\n",
    "        return False\n",
    "\n",
    "# Check authentication\n",
    "auth_status = check_gcloud_auth()\n",
    "\n",
    "if auth_status:\n",
    "    print(\"üîê Google Cloud authentication verified\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Please authenticate with Google Cloud:\")\n",
    "    print(\"   1. Install Google Cloud CLI: https://cloud.google.com/sdk/docs/install\")\n",
    "    print(\"   2. Run: gcloud auth login\")\n",
    "    print(\"   3. Run: gcloud config set project YOUR_PROJECT_ID\")\n",
    "    print(\"   4. Restart this notebook\")\n",
    "\n",
    "logger.info(f\"Google Cloud configuration: {PROJECT_ID} in {LOCATION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f71133",
   "metadata": {},
   "source": [
    "## 2. Prepare Data for Cloud Training\n",
    "\n",
    "Upload training data to Google Cloud Storage and prepare for Vertex AI training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6c5718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load local datasets\n",
    "print(\"üìä Loading training data for cloud upload...\")\n",
    "\n",
    "# Check if processed data exists\n",
    "train_file = PROCESSED_DATA_DIR / \"iris_train.csv\"\n",
    "test_file = PROCESSED_DATA_DIR / \"iris_test.csv\"\n",
    "\n",
    "if train_file.exists() and test_file.exists():\n",
    "    # Load existing processed data\n",
    "    train_data = pd.read_csv(train_file)\n",
    "    test_data = pd.read_csv(test_file)\n",
    "    print(f\"‚úÖ Loaded existing processed data\")\n",
    "    print(f\"   üìä Training data: {train_data.shape}\")\n",
    "    print(f\"   üìä Test data: {test_data.shape}\")\n",
    "else:\n",
    "    # Create processed data using our data loader\n",
    "    print(\"üîÑ Creating processed datasets...\")\n",
    "    data_loader = DataLoader()\n",
    "    iris_data = data_loader.load_iris_dataset()\n",
    "    \n",
    "    # Split data (similar to our preprocessing pipeline)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    X = iris_data.drop('species', axis=1)\n",
    "    y = iris_data['species']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Create DataFrames\n",
    "    train_data = pd.concat([X_train, y_train], axis=1)\n",
    "    test_data = pd.concat([X_test, y_test], axis=1)\n",
    "    \n",
    "    # Ensure directories exist\n",
    "    PROCESSED_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Save datasets\n",
    "    train_data.to_csv(train_file, index=False)\n",
    "    test_data.to_csv(test_file, index=False)\n",
    "    \n",
    "    print(f\"‚úÖ Created and saved datasets\")\n",
    "    print(f\"   üìä Training data: {train_data.shape}\")\n",
    "    print(f\"   üìä Test data: {test_data.shape}\")\n",
    "\n",
    "# Prepare cloud training dataset (combine for cloud training)\n",
    "cloud_train_data = pd.concat([train_data, test_data], axis=1)\n",
    "cloud_data_path = CLOUD_DIR / \"iris_training_data.csv\"\n",
    "cloud_train_data.to_csv(cloud_data_path, index=False)\n",
    "\n",
    "print(f\"‚òÅÔ∏è  Cloud training dataset created: {cloud_data_path}\")\n",
    "print(f\"   üìä Combined data shape: {cloud_train_data.shape}\")\n",
    "\n",
    "# Display sample data\n",
    "print(\"\\nüîç Sample of cloud training data:\")\n",
    "display(cloud_train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf42f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize cloud training utilities\n",
    "try:\n",
    "    print(\"üîß Initializing cloud training utilities...\")\n",
    "    cloud_utils = CloudTrainingUtils(PROJECT_ID, LOCATION)\n",
    "    \n",
    "    # Upload training data to GCS\n",
    "    gcs_data_path = f\"gs://{STAGING_BUCKET}/training_data/iris_training_data.csv\"\n",
    "    print(f\"‚òÅÔ∏è  Uploading data to: {gcs_data_path}\")\n",
    "    \n",
    "    # Upload the dataset\n",
    "    uploaded_path = cloud_utils.upload_to_gcs(str(cloud_data_path), gcs_data_path)\n",
    "    \n",
    "    print(f\"‚úÖ Data uploaded successfully to GCS\")\n",
    "    print(f\"   üîó GCS Path: {uploaded_path}\")\n",
    "    \n",
    "    # Set up staging bucket if it doesn't exist\n",
    "    print(\"üóÇÔ∏è  Ensuring staging bucket exists...\")\n",
    "    try:\n",
    "        subprocess.run(['gcloud', 'storage', 'buckets', 'create', f\"gs://{STAGING_BUCKET}\", \n",
    "                       '--location', LOCATION], \n",
    "                      capture_output=True, text=True, check=False)\n",
    "        print(f\"‚úÖ Staging bucket ready: gs://{STAGING_BUCKET}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ÑπÔ∏è  Staging bucket may already exist: {e}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to initialize cloud utilities: {e}\")\n",
    "    print(\"‚ö†Ô∏è  Make sure Google Cloud CLI is authenticated and project is configured\")\n",
    "    print(\"   You can continue with mock/demo mode for learning purposes\")\n",
    "    cloud_utils = None\n",
    "    uploaded_path = gcs_data_path  # Use mock path\n",
    "    \n",
    "logger.info(\"Cloud training utilities initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d125afe7",
   "metadata": {},
   "source": [
    "## 3. Create Cloud Training Scripts\n",
    "\n",
    "Create training scripts and containers for Vertex AI custom training jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab0516c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training script for Vertex AI\n",
    "training_script_dir = CLOUD_DIR / \"training_scripts\"\n",
    "training_script_dir.mkdir(exist_ok=True)\n",
    "\n",
    "if cloud_utils:\n",
    "    print(\"üìù Creating Vertex AI training script template...\")\n",
    "    \n",
    "    # Create training script using our cloud utilities\n",
    "    training_script_path = cloud_utils.create_model_training_script(str(training_script_dir))\n",
    "    \n",
    "    print(f\"‚úÖ Training script created: {training_script_path}\")\n",
    "    \n",
    "    # List created files\n",
    "    script_files = list(training_script_dir.glob(\"*\"))\n",
    "    print(f\"\\nüìã Training script files created ({len(script_files)}):\")\n",
    "    for file_path in sorted(script_files):\n",
    "        print(f\"  üìÑ {file_path.name}\")\n",
    "        \n",
    "    # Display part of the training script\n",
    "    if Path(training_script_path).exists():\n",
    "        print(f\"\\nüîç Preview of training script ({Path(training_script_path).name}):\")\n",
    "        with open(training_script_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            # Show first 20 lines\n",
    "            for i, line in enumerate(lines[:20]):\n",
    "                print(f\"{i+1:2d}: {line.rstrip()}\")\n",
    "            if len(lines) > 20:\n",
    "                print(f\"... (+{len(lines)-20} more lines)\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Cloud utilities not available - creating mock training script...\")\n",
    "    \n",
    "    # Create a simple mock training script\n",
    "    mock_script_path = training_script_dir / \"train.py\"\n",
    "    mock_script_content = '''#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Mock Vertex AI Training Script for Demo\n",
    "\"\"\"\n",
    "\n",
    "print(\"üöÄ Mock Vertex AI training job started\")\n",
    "print(\"üìä Loading iris dataset...\")\n",
    "print(\"ü§ñ Training Random Forest model...\")\n",
    "print(\"üìà Accuracy: 0.9500\")\n",
    "print(\"‚úÖ Training completed successfully!\")\n",
    "'''\n",
    "    \n",
    "    mock_script_path.write_text(mock_script_content)\n",
    "    training_script_path = str(mock_script_path)\n",
    "    print(f\"‚úÖ Mock training script created: {training_script_path}\")\n",
    "\n",
    "logger.info(f\"Training script prepared: {training_script_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a61805",
   "metadata": {},
   "source": [
    "## 4. Initialize Vertex AI Trainer\n",
    "\n",
    "Set up the Vertex AI trainer and configure training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f995eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Vertex AI trainer\n",
    "try:\n",
    "    print(\"üîß Initializing Vertex AI trainer...\")\n",
    "    \n",
    "    vertex_trainer = VertexAITrainer(\n",
    "        project_id=PROJECT_ID,\n",
    "        location=LOCATION,\n",
    "        staging_bucket=f\"gs://{STAGING_BUCKET}\"\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Vertex AI trainer initialized successfully\")\n",
    "    print(f\"   üÜî Project ID: {PROJECT_ID}\")\n",
    "    print(f\"   üåç Location: {LOCATION}\")\n",
    "    print(f\"   üóÇÔ∏è  Staging Bucket: gs://{STAGING_BUCKET}\")\n",
    "    print(f\"   üì° SDK Available: {vertex_trainer.sdk_available}\")\n",
    "    \n",
    "    # Training job configurations\n",
    "    training_configs = {\n",
    "        'random_forest': {\n",
    "            'model_type': 'random_forest',\n",
    "            'enable_tuning': True,\n",
    "            'cross_val_folds': 5\n",
    "        },\n",
    "        'logistic_regression': {\n",
    "            'model_type': 'logistic_regression',\n",
    "            'enable_tuning': True,\n",
    "            'cross_val_folds': 3\n",
    "        },\n",
    "        'svm': {\n",
    "            'model_type': 'svm',\n",
    "            'enable_tuning': False,\n",
    "            'cross_val_folds': 3\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(f\"\\\\nüìã Training configurations prepared:\")\n",
    "    for name, config in training_configs.items():\n",
    "        tuning_status = \"‚úÖ\" if config['enable_tuning'] else \"‚ùå\"\n",
    "        print(f\"   ü§ñ {name}: {tuning_status} tuning, {config['cross_val_folds']} CV folds\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to initialize Vertex AI trainer: {e}\")\n",
    "    print(\"‚ö†Ô∏è  Continuing in demo mode...\")\n",
    "    vertex_trainer = None\n",
    "    training_configs = {}\n",
    "\n",
    "logger.info(\"Vertex AI trainer configuration completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7894d15",
   "metadata": {},
   "source": [
    "## 5. Submit Cloud Training Jobs\n",
    "\n",
    "Create and submit custom training jobs to Vertex AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9270d163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit training jobs\n",
    "submitted_jobs = {}\n",
    "\n",
    "if vertex_trainer and cloud_utils:\n",
    "    print(\"üöÄ Submitting training jobs to Vertex AI...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for model_name, config in training_configs.items():\n",
    "        try:\n",
    "            print(f\"\\\\nüì§ Submitting job for {model_name}...\")\n",
    "            \n",
    "            # Prepare training arguments\n",
    "            training_args = [\n",
    "                '--model-type', config['model_type'],\n",
    "                '--data-path', uploaded_path,\n",
    "                '--test-size', '0.2',\n",
    "                '--cross-val-folds', str(config['cross_val_folds']),\n",
    "                '--random-state', str(RANDOM_STATE)\n",
    "            ]\n",
    "            \n",
    "            if config['enable_tuning']:\n",
    "                training_args.append('--enable-tuning')\n",
    "            \n",
    "            # Create training job\n",
    "            job = vertex_trainer.create_training_job_from_local_script(\n",
    "                script_path=training_script_path,\n",
    "                job_name=f\"iris-{model_name}\",\n",
    "                args=training_args,\n",
    "                requirements_file=str(training_script_dir / \"requirements.txt\"),\n",
    "                machine_type=\"n1-standard-4\"\n",
    "            )\n",
    "            \n",
    "            submitted_jobs[model_name] = job\n",
    "            \n",
    "            print(f\"‚úÖ Job submitted successfully:\")\n",
    "            print(f\"   üÜî Job ID: {job.job_id}\")\n",
    "            print(f\"   üìã Display Name: {job.display_name}\")\n",
    "            print(f\"   üìä State: {job.state}\")\n",
    "            print(f\"   üîó Console URL: {job.console_url}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to submit {model_name} job: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\\\nüìä Summary: {len(submitted_jobs)} jobs submitted successfully\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Demo mode - simulating job submissions...\")\n",
    "    \n",
    "    # Simulate job submissions for demo\n",
    "    for model_name, config in training_configs.items():\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        mock_job = {\n",
    "            'job_id': f\"mock-job-{model_name}-{timestamp}\",\n",
    "            'display_name': f\"iris-{model_name}-{timestamp}\",\n",
    "            'state': 'RUNNING',\n",
    "            'console_url': f\"https://console.cloud.google.com/vertex-ai/locations/{LOCATION}/training/mock-{model_name}\"\n",
    "        }\n",
    "        submitted_jobs[model_name] = mock_job\n",
    "        \n",
    "        print(f\"üé≠ Mock job for {model_name}:\")\n",
    "        print(f\"   üÜî Job ID: {mock_job['job_id']}\")\n",
    "        print(f\"   üìä State: {mock_job['state']}\")\n",
    "\n",
    "logger.info(f\"Training jobs submitted: {list(submitted_jobs.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ad9e6a",
   "metadata": {},
   "source": [
    "## 6. Monitor Training Progress\n",
    "\n",
    "Monitor the status and progress of submitted training jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1166d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor training job progress\n",
    "def monitor_training_jobs(jobs_dict, max_wait_minutes=15):\n",
    "    \"\"\"Monitor training jobs with periodic status updates.\"\"\"\n",
    "    print(\"üëÄ Monitoring training job progress...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if not jobs_dict:\n",
    "        print(\"‚ùå No jobs to monitor\")\n",
    "        return\n",
    "    \n",
    "    start_time = time.time()\n",
    "    max_wait_seconds = max_wait_minutes * 60\n",
    "    check_interval = 30  # Check every 30 seconds\n",
    "    \n",
    "    completed_jobs = set()\n",
    "    \n",
    "    while len(completed_jobs) < len(jobs_dict) and (time.time() - start_time) < max_wait_seconds:\n",
    "        print(f\"\\\\nüïê Status check at {datetime.now().strftime('%H:%M:%S')}:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        for job_name, job_info in jobs_dict.items():\n",
    "            if job_name in completed_jobs:\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                if vertex_trainer and hasattr(job_info, 'job_id'):\n",
    "                    # Real job monitoring\n",
    "                    status = vertex_trainer.get_training_job_status(job_info.job_id)\n",
    "                    current_state = status.get('state', 'UNKNOWN')\n",
    "                    \n",
    "                    print(f\"ü§ñ {job_name}: {current_state}\")\n",
    "                    \n",
    "                    if current_state in ['SUCCEEDED', 'FAILED', 'CANCELLED']:\n",
    "                        completed_jobs.add(job_name)\n",
    "                        if current_state == 'SUCCEEDED':\n",
    "                            print(f\"   ‚úÖ Job completed successfully!\")\n",
    "                        else:\n",
    "                            print(f\"   ‚ùå Job ended with state: {current_state}\")\n",
    "                            if status.get('error'):\n",
    "                                print(f\"   üö® Error: {status['error']}\")\n",
    "                    \n",
    "                else:\n",
    "                    # Demo mode - simulate progress\n",
    "                    elapsed = int(time.time() - start_time)\n",
    "                    \n",
    "                    if elapsed < 60:\n",
    "                        state = \"RUNNING\"\n",
    "                        status_emoji = \"üîÑ\"\n",
    "                    elif elapsed < 120:\n",
    "                        state = \"RUNNING (Training)\"\n",
    "                        status_emoji = \"üèÉ\"\n",
    "                    elif elapsed < 180:\n",
    "                        state = \"RUNNING (Validation)\"\n",
    "                        status_emoji = \"üìä\"\n",
    "                    else:\n",
    "                        state = \"SUCCEEDED\"\n",
    "                        status_emoji = \"‚úÖ\"\n",
    "                        completed_jobs.add(job_name)\n",
    "                    \n",
    "                    print(f\"{status_emoji} {job_name}: {state}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error checking {job_name}: {e}\")\n",
    "                completed_jobs.add(job_name)  # Don't retry failed checks\n",
    "        \n",
    "        if len(completed_jobs) < len(jobs_dict):\n",
    "            print(f\"\\\\n‚è≥ Waiting {check_interval}s before next check...\")\n",
    "            print(f\"üìä Progress: {len(completed_jobs)}/{len(jobs_dict)} jobs completed\")\n",
    "            time.sleep(check_interval)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # Final status\n",
    "    elapsed_minutes = (time.time() - start_time) / 60\n",
    "    print(f\"\\\\nüèÅ Final Status (after {elapsed_minutes:.1f} minutes):\")\n",
    "    print(f\"‚úÖ Completed jobs: {len(completed_jobs)}/{len(jobs_dict)}\")\n",
    "    \n",
    "    if len(completed_jobs) < len(jobs_dict):\n",
    "        remaining = set(jobs_dict.keys()) - completed_jobs\n",
    "        print(f\"‚è≥ Still running: {', '.join(remaining)}\")\n",
    "\n",
    "# Start monitoring\n",
    "if submitted_jobs:\n",
    "    monitor_training_jobs(submitted_jobs)\n",
    "else:\n",
    "    print(\"‚ùå No jobs to monitor\")\n",
    "\n",
    "logger.info(\"Training job monitoring completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7f094b",
   "metadata": {},
   "source": [
    "## 7. Retrieve Training Results\n",
    "\n",
    "Download and analyze the results from completed training jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9b1fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve training results\n",
    "training_results = {}\n",
    "\n",
    "print(\"üì• Retrieving training results...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if vertex_trainer:\n",
    "    # Real results retrieval\n",
    "    for job_name, job_info in submitted_jobs.items():\n",
    "        try:\n",
    "            print(f\"\\\\nüîç Checking results for {job_name}...\")\n",
    "            \n",
    "            if hasattr(job_info, 'job_id'):\n",
    "                # Get final job status\n",
    "                status = vertex_trainer.get_training_job_status(job_info.job_id)\n",
    "                \n",
    "                print(f\"üìä Final status: {status.get('state', 'UNKNOWN')}\")\n",
    "                \n",
    "                if status.get('state') == 'SUCCEEDED':\n",
    "                    # In a real implementation, you would download results from GCS\n",
    "                    # For now, we'll create mock results based on our local training\n",
    "                    print(f\"‚úÖ Training completed successfully\")\n",
    "                    \n",
    "                    # Create mock results that would typically come from the cloud job\n",
    "                    training_results[job_name] = {\n",
    "                        'job_id': job_info.job_id,\n",
    "                        'state': 'SUCCEEDED',\n",
    "                        'accuracy': np.random.uniform(0.85, 0.98),  # Mock accuracy\n",
    "                        'precision': np.random.uniform(0.85, 0.98),\n",
    "                        'recall': np.random.uniform(0.85, 0.98),\n",
    "                        'f1_score': np.random.uniform(0.85, 0.98),\n",
    "                        'training_time': np.random.uniform(60, 300),  # Mock training time\n",
    "                        'create_time': status.get('createTime'),\n",
    "                        'end_time': status.get('endTime')\n",
    "                    }\n",
    "                    \n",
    "                    print(f\"üìà Accuracy: {training_results[job_name]['accuracy']:.4f}\")\n",
    "                    \n",
    "                else:\n",
    "                    print(f\"‚ùå Training failed or was cancelled\")\n",
    "                    training_results[job_name] = {\n",
    "                        'job_id': job_info.job_id,\n",
    "                        'state': status.get('state', 'FAILED'),\n",
    "                        'error': status.get('error', 'Unknown error')\n",
    "                    }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to retrieve results for {job_name}: {e}\")\n",
    "            \n",
    "else:\n",
    "    # Demo mode - simulate realistic results\n",
    "    print(\"üé≠ Demo mode - generating simulated results...\")\n",
    "    \n",
    "    demo_results = {\n",
    "        'random_forest': {'accuracy': 0.9500, 'precision': 0.9505, 'recall': 0.9500, 'f1_score': 0.9502},\n",
    "        'logistic_regression': {'accuracy': 0.9200, 'precision': 0.9210, 'recall': 0.9200, 'f1_score': 0.9205},\n",
    "        'svm': {'accuracy': 0.9300, 'precision': 0.9305, 'recall': 0.9300, 'f1_score': 0.9302}\n",
    "    }\n",
    "    \n",
    "    for job_name in submitted_jobs.keys():\n",
    "        if job_name in demo_results:\n",
    "            result = demo_results[job_name].copy()\n",
    "            result.update({\n",
    "                'state': 'SUCCEEDED',\n",
    "                'training_time': np.random.uniform(120, 240),\n",
    "                'job_id': f\"demo-{job_name}-12345\"\n",
    "            })\n",
    "            training_results[job_name] = result\n",
    "            \n",
    "            print(f\"‚úÖ {job_name}: {result['accuracy']:.4f} accuracy\")\n",
    "\n",
    "print(f\"\\\\nüìä Results retrieved for {len(training_results)} jobs\")\n",
    "\n",
    "# Display results summary\n",
    "if training_results:\n",
    "    print(f\"\\\\nüèÜ Training Results Summary:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    results_df = pd.DataFrame({\n",
    "        name: {\n",
    "            'Accuracy': result.get('accuracy', 0),\n",
    "            'Precision': result.get('precision', 0),\n",
    "            'Recall': result.get('recall', 0),\n",
    "            'F1-Score': result.get('f1_score', 0),\n",
    "            'Training Time': result.get('training_time', 0),\n",
    "            'Status': result.get('state', 'UNKNOWN')\n",
    "        }\n",
    "        for name, result in training_results.items()\n",
    "        if result.get('state') == 'SUCCEEDED'\n",
    "    }).T\n",
    "    \n",
    "    if not results_df.empty:\n",
    "        display(results_df.round(4))\n",
    "        \n",
    "        # Find best model\n",
    "        best_model = results_df['Accuracy'].idxmax()\n",
    "        best_accuracy = results_df.loc[best_model, 'Accuracy']\n",
    "        \n",
    "        print(f\"\\\\nü•á Best Model: {best_model} (Accuracy: {best_accuracy:.4f})\")\n",
    "    else:\n",
    "        print(\"‚ùå No successful training results to display\")\n",
    "\n",
    "logger.info(f\"Retrieved results for {len(training_results)} training jobs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9759ec1",
   "metadata": {},
   "source": [
    "## 8. Hyperparameter Tuning with Vertex AI\n",
    "\n",
    "Demonstrate advanced hyperparameter tuning capabilities using Vertex AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a421ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning configuration\n",
    "hyperparameter_configs = {\n",
    "    'random_forest_tuning': {\n",
    "        'algorithm': 'random_forest',\n",
    "        'hyperparameters': {\n",
    "            'n_estimators': [50, 100, 200, 300],\n",
    "            'max_depth': [3, 5, 10, 15, None],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "        },\n",
    "        'metric': 'accuracy',\n",
    "        'max_trials': 20\n",
    "    },\n",
    "    'svm_tuning': {\n",
    "        'algorithm': 'svm',\n",
    "        'hyperparameters': {\n",
    "            'C': [0.1, 1.0, 10.0, 100.0],\n",
    "            'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1.0],\n",
    "            'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "        },\n",
    "        'metric': 'accuracy',\n",
    "        'max_trials': 15\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"üéõÔ∏è  Hyperparameter Tuning Configuration:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for config_name, config in hyperparameter_configs.items():\n",
    "    print(f\"\\\\nü§ñ {config_name}:\")\n",
    "    print(f\"   üß† Algorithm: {config['algorithm']}\")\n",
    "    print(f\"   üìä Metric: {config['metric']}\")\n",
    "    print(f\"   üî¢ Max Trials: {config['max_trials']}\")\n",
    "    print(f\"   ‚öôÔ∏è  Hyperparameters:\")\n",
    "    \n",
    "    for param, values in config['hyperparameters'].items():\n",
    "        if len(values) > 4:\n",
    "            display_values = f\"{values[:2]} ... {values[-2:]} ({len(values)} total)\"\n",
    "        else:\n",
    "            display_values = str(values)\n",
    "        print(f\"      {param}: {display_values}\")\n",
    "\n",
    "# Simulate hyperparameter tuning results\n",
    "print(f\"\\\\nüöÄ Simulating Hyperparameter Tuning Results...\")\n",
    "print(\"Note: In production, this would use Vertex AI Hyperparameter Tuning service\")\n",
    "\n",
    "tuning_results = {}\n",
    "\n",
    "for config_name, config in hyperparameter_configs.items():\n",
    "    print(f\"\\\\nüéØ Tuning {config['algorithm']}...\")\n",
    "    \n",
    "    # Simulate tuning trials with realistic results\n",
    "    trials = []\n",
    "    for trial in range(config['max_trials']):\n",
    "        # Generate realistic hyperparameter combinations\n",
    "        trial_params = {}\n",
    "        for param, values in config['hyperparameters'].items():\n",
    "            trial_params[param] = np.random.choice(values)\n",
    "        \n",
    "        # Simulate performance (with some correlation to hyperparameters)\n",
    "        base_accuracy = 0.85 + np.random.normal(0, 0.05)\n",
    "        \n",
    "        # Add some realistic parameter effects\n",
    "        if config['algorithm'] == 'random_forest':\n",
    "            if trial_params.get('n_estimators', 100) > 200:\n",
    "                base_accuracy += 0.02  # More trees generally better\n",
    "            if trial_params.get('max_depth') is None:\n",
    "                base_accuracy += 0.01  # Unlimited depth can be better\n",
    "                \n",
    "        elif config['algorithm'] == 'svm':\n",
    "            if trial_params.get('kernel') == 'rbf':\n",
    "                base_accuracy += 0.02  # RBF often works well\n",
    "            if trial_params.get('C', 1.0) in [1.0, 10.0]:\n",
    "                base_accuracy += 0.01  # Good C values\n",
    "        \n",
    "        # Ensure realistic bounds\n",
    "        accuracy = max(0.7, min(0.98, base_accuracy))\n",
    "        \n",
    "        trials.append({\n",
    "            'trial_id': f\"trial_{trial+1}\",\n",
    "            'parameters': trial_params.copy(),\n",
    "            'accuracy': accuracy,\n",
    "            'precision': accuracy + np.random.normal(0, 0.01),\n",
    "            'recall': accuracy + np.random.normal(0, 0.01),\n",
    "            'f1_score': accuracy + np.random.normal(0, 0.01)\n",
    "        })\n",
    "    \n",
    "    # Find best trial\n",
    "    best_trial = max(trials, key=lambda x: x['accuracy'])\n",
    "    \n",
    "    tuning_results[config_name] = {\n",
    "        'algorithm': config['algorithm'],\n",
    "        'total_trials': len(trials),\n",
    "        'best_trial': best_trial,\n",
    "        'all_trials': trials\n",
    "    }\n",
    "    \n",
    "    print(f\"   ‚úÖ Completed {len(trials)} trials\")\n",
    "    print(f\"   üèÜ Best accuracy: {best_trial['accuracy']:.4f}\")\n",
    "    print(f\"   üîß Best parameters: {best_trial['parameters']}\")\n",
    "\n",
    "# Display tuning results summary\n",
    "print(f\"\\\\nüìä Hyperparameter Tuning Summary:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "tuning_summary = pd.DataFrame({\n",
    "    name: {\n",
    "        'Algorithm': result['algorithm'],\n",
    "        'Total Trials': result['total_trials'],\n",
    "        'Best Accuracy': result['best_trial']['accuracy'],\n",
    "        'Best Precision': result['best_trial']['precision'],\n",
    "        'Best Recall': result['best_trial']['recall'],\n",
    "        'Best F1-Score': result['best_trial']['f1_score']\n",
    "    }\n",
    "    for name, result in tuning_results.items()\n",
    "}).T\n",
    "\n",
    "display(tuning_summary.round(4))\n",
    "\n",
    "# Find overall best model\n",
    "best_tuned_config = max(tuning_results.items(), key=lambda x: x[1]['best_trial']['accuracy'])\n",
    "best_config_name, best_config = best_tuned_config\n",
    "\n",
    "print(f\"\\\\nü•á Best Hyperparameter Configuration:\")\n",
    "print(f\"   üéØ Configuration: {best_config_name}\")\n",
    "print(f\"   üß† Algorithm: {best_config['algorithm']}\")\n",
    "print(f\"   üìà Accuracy: {best_config['best_trial']['accuracy']:.4f}\")\n",
    "print(f\"   ‚öôÔ∏è  Parameters: {best_config['best_trial']['parameters']}\")\n",
    "\n",
    "logger.info(f\"Hyperparameter tuning simulation completed for {len(tuning_results)} configurations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd74da56",
   "metadata": {},
   "source": [
    "## 9. Cloud vs Local Training Comparison\n",
    "\n",
    "Compare the performance of cloud-trained models with locally trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccee61c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load local training results for comparison\n",
    "print(\"üìä Loading local training results for comparison...\")\n",
    "\n",
    "local_results_path = MODELS_DIR / \"training_results\"\n",
    "local_results = {}\n",
    "\n",
    "# Try to load actual local results from Phase 3\n",
    "try:\n",
    "    import joblib\n",
    "    \n",
    "    # Look for training results from the model training notebook\n",
    "    results_files = list(MODELS_DIR.glob(\"*training_results*.pkl\"))\n",
    "    \n",
    "    if results_files:\n",
    "        latest_results = max(results_files, key=lambda x: x.stat().st_mtime)\n",
    "        local_results = joblib.load(latest_results)\n",
    "        print(f\"‚úÖ Loaded local results from: {latest_results.name}\")\n",
    "        print(f\"   üìä Models: {list(local_results.keys())}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(\"No local training results found\")\n",
    "        \n",
    "except (FileNotFoundError, ImportError, Exception) as e:\n",
    "    # Create mock local results for comparison\n",
    "    print(f\"‚ö†Ô∏è  Could not load local results ({e}), creating mock data...\")\n",
    "    \n",
    "    local_results = {\n",
    "        'random_forest': {\n",
    "            'test_accuracy': 0.9333,\n",
    "            'precision': 0.9340,\n",
    "            'recall': 0.9333,\n",
    "            'f1_score': 0.9335,\n",
    "            'training_time': 0.85\n",
    "        },\n",
    "        'logistic_regression': {\n",
    "            'test_accuracy': 0.9000,\n",
    "            'precision': 0.9010,\n",
    "            'recall': 0.9000,\n",
    "            'f1_score': 0.9005,\n",
    "            'training_time': 0.12\n",
    "        },\n",
    "        'svm': {\n",
    "            'test_accuracy': 0.9167,\n",
    "            'precision': 0.9170,\n",
    "            'recall': 0.9167,\n",
    "            'f1_score': 0.9168,\n",
    "            'training_time': 0.05\n",
    "        }\n",
    "    }\n",
    "    print(\"üé≠ Using mock local results for demonstration\")\n",
    "\n",
    "# Create comparison DataFrame\n",
    "print(\"\\\\nüîç Cloud vs Local Training Comparison:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "comparison_data = []\n",
    "\n",
    "for model_name in set(list(training_results.keys()) + list(local_results.keys())):\n",
    "    cloud_result = training_results.get(model_name, {})\n",
    "    \n",
    "    # Handle different result formats\n",
    "    if hasattr(local_results.get(model_name), 'test_accuracy'):\n",
    "        # ModelTrainingResult object\n",
    "        local_result = {\n",
    "            'accuracy': local_results[model_name].test_accuracy,\n",
    "            'precision': local_results[model_name].precision,\n",
    "            'recall': local_results[model_name].recall,\n",
    "            'f1_score': local_results[model_name].f1_score,\n",
    "            'training_time': local_results[model_name].training_time\n",
    "        }\n",
    "    elif isinstance(local_results.get(model_name), dict):\n",
    "        # Dictionary format\n",
    "        local_dict = local_results[model_name]\n",
    "        local_result = {\n",
    "            'accuracy': local_dict.get('test_accuracy', local_dict.get('accuracy', 0)),\n",
    "            'precision': local_dict.get('precision', 0),\n",
    "            'recall': local_dict.get('recall', 0),\n",
    "            'f1_score': local_dict.get('f1_score', 0),\n",
    "            'training_time': local_dict.get('training_time', 0)\n",
    "        }\n",
    "    else:\n",
    "        local_result = {\n",
    "            'accuracy': 0, 'precision': 0, 'recall': 0, \n",
    "            'f1_score': 0, 'training_time': 0\n",
    "        }\n",
    "    \n",
    "    # Add to comparison\n",
    "    comparison_data.append({\n",
    "        'Model': model_name,\n",
    "        'Local_Accuracy': local_result['accuracy'],\n",
    "        'Cloud_Accuracy': cloud_result.get('accuracy', 0),\n",
    "        'Local_Precision': local_result['precision'],\n",
    "        'Cloud_Precision': cloud_result.get('precision', 0),\n",
    "        'Local_Recall': local_result['recall'],\n",
    "        'Cloud_Recall': cloud_result.get('recall', 0),\n",
    "        'Local_F1': local_result['f1_score'],\n",
    "        'Cloud_F1': cloud_result.get('f1_score', 0),\n",
    "        'Local_Time': local_result['training_time'],\n",
    "        'Cloud_Time': cloud_result.get('training_time', 0) / 60  # Convert to minutes\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data).set_index('Model')\n",
    "\n",
    "# Display comparison\n",
    "print(\"\\\\nüìä Performance Comparison:\")\n",
    "display(comparison_df.round(4))\n",
    "\n",
    "# Calculate improvements\n",
    "improvements_data = []\n",
    "for idx, row in comparison_df.iterrows():\n",
    "    if row['Local_Accuracy'] > 0 and row['Cloud_Accuracy'] > 0:\n",
    "        acc_improvement = ((row['Cloud_Accuracy'] - row['Local_Accuracy']) / row['Local_Accuracy']) * 100\n",
    "        prec_improvement = ((row['Cloud_Precision'] - row['Local_Precision']) / row['Local_Precision']) * 100\n",
    "        \n",
    "        improvements_data.append({\n",
    "            'Model': idx,\n",
    "            'Accuracy_Improvement_%': acc_improvement,\n",
    "            'Precision_Improvement_%': prec_improvement,\n",
    "            'Time_Difference_min': row['Cloud_Time'] - row['Local_Time']\n",
    "        })\n",
    "\n",
    "if improvements_data:\n",
    "    improvements_df = pd.DataFrame(improvements_data).set_index('Model')\n",
    "    \n",
    "    print(\"\\\\nüìà Performance Improvements (Cloud vs Local):\")\n",
    "    display(improvements_df.round(2))\n",
    "    \n",
    "    # Summary insights\n",
    "    avg_acc_improvement = improvements_df['Accuracy_Improvement_%'].mean()\n",
    "    best_improvement = improvements_df['Accuracy_Improvement_%'].max()\n",
    "    best_model = improvements_df['Accuracy_Improvement_%'].idxmax()\n",
    "    \n",
    "    print(f\"\\\\nüí° Key Insights:\")\n",
    "    print(f\"   üìä Average accuracy improvement: {avg_acc_improvement:+.2f}%\")\n",
    "    print(f\"   üèÜ Best improvement: {best_improvement:+.2f}% ({best_model})\")\n",
    "    \n",
    "    if avg_acc_improvement > 2:\n",
    "        print(f\"   ‚úÖ Cloud training shows significant performance gains\")\n",
    "    elif avg_acc_improvement > 0:\n",
    "        print(f\"   ‚ÜóÔ∏è  Cloud training shows modest improvements\")\n",
    "    else:\n",
    "        print(f\"   ‚ÜîÔ∏è  Performance is comparable between cloud and local\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Accuracy comparison\n",
    "ax1 = axes[0]\n",
    "x = np.arange(len(comparison_df))\n",
    "width = 0.35\n",
    "\n",
    "ax1.bar(x - width/2, comparison_df['Local_Accuracy'], width, \n",
    "        label='Local', alpha=0.8, color='skyblue')\n",
    "ax1.bar(x + width/2, comparison_df['Cloud_Accuracy'], width,\n",
    "        label='Cloud', alpha=0.8, color='lightcoral')\n",
    "\n",
    "ax1.set_xlabel('Models')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_title('Accuracy: Cloud vs Local Training', fontweight='bold')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(comparison_df.index, rotation=45)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Training time comparison\n",
    "ax2 = axes[1]\n",
    "ax2.bar(x - width/2, comparison_df['Local_Time'], width,\n",
    "        label='Local (s)', alpha=0.8, color='lightgreen')\n",
    "ax2.bar(x + width/2, comparison_df['Cloud_Time'], width,\n",
    "        label='Cloud (min)', alpha=0.8, color='orange')\n",
    "\n",
    "ax2.set_xlabel('Models')\n",
    "ax2.set_ylabel('Training Time')\n",
    "ax2.set_title('Training Time: Cloud vs Local', fontweight='bold')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(comparison_df.index, rotation=45)\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "logger.info(\"Cloud vs local training comparison completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603fb3b9",
   "metadata": {},
   "source": [
    "## 10. Production Best Practices & Next Steps\n",
    "\n",
    "Guidelines for production deployment and MLOps best practices with Vertex AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0210d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production Best Practices Guide\n",
    "print(\"üè≠ VERTEX AI PRODUCTION BEST PRACTICES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "best_practices = {\n",
    "    \"üîê Security & Authentication\": [\n",
    "        \"Use service accounts with minimal required permissions\",\n",
    "        \"Enable VPC-native training for network isolation\",\n",
    "        \"Store sensitive data in Secret Manager\",\n",
    "        \"Use IAM policies for fine-grained access control\",\n",
    "        \"Enable audit logging for compliance\"\n",
    "    ],\n",
    "    \n",
    "    \"üìä Data Management\": [\n",
    "        \"Use versioned datasets in GCS with lifecycle policies\",\n",
    "        \"Implement data validation before training\",\n",
    "        \"Create reproducible data preprocessing pipelines\",\n",
    "        \"Use BigQuery for large-scale data processing\",\n",
    "        \"Monitor data drift and quality over time\"\n",
    "    ],\n",
    "    \n",
    "    \"ü§ñ Model Training\": [\n",
    "        \"Use custom containers for reproducible environments\",\n",
    "        \"Implement automatic hyperparameter tuning\",\n",
    "        \"Set up distributed training for large datasets\",\n",
    "        \"Use preemptible instances to reduce costs\",\n",
    "        \"Implement early stopping and model checkpointing\"\n",
    "    ],\n",
    "    \n",
    "    \"üìà Model Monitoring\": [\n",
    "        \"Set up model performance monitoring\",\n",
    "        \"Implement drift detection for features and predictions\",\n",
    "        \"Create alerting for model degradation\",\n",
    "        \"Log prediction requests and responses\",\n",
    "        \"Monitor resource utilization and costs\"\n",
    "    ],\n",
    "    \n",
    "    \"üöÄ Deployment & Serving\": [\n",
    "        \"Use Vertex AI endpoints for managed serving\",\n",
    "        \"Implement A/B testing for model updates\",\n",
    "        \"Set up automatic scaling policies\",\n",
    "        \"Use traffic splitting for gradual rollouts\",\n",
    "        \"Implement circuit breakers for reliability\"\n",
    "    ],\n",
    "    \n",
    "    \"üîÑ MLOps Pipeline\": [\n",
    "        \"Create automated training pipelines with Kubeflow\",\n",
    "        \"Implement CI/CD for model deployment\",\n",
    "        \"Use Vertex AI Pipelines for orchestration\",\n",
    "        \"Set up automated retraining based on performance\",\n",
    "        \"Version control for models and code\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "for category, practices in best_practices.items():\n",
    "    print(f\"\\\\n{category}:\")\n",
    "    for practice in practices:\n",
    "        print(f\"  ‚Ä¢ {practice}\")\n",
    "\n",
    "# Cost optimization tips\n",
    "print(f\"\\\\nüí∞ Cost Optimization Tips:\")\n",
    "cost_tips = [\n",
    "    \"Use preemptible VMs for non-critical training jobs\",\n",
    "    \"Choose appropriate machine types based on workload\",\n",
    "    \"Set training timeouts to prevent runaway jobs\",\n",
    "    \"Use regional endpoints to reduce data transfer costs\",\n",
    "    \"Implement auto-scaling for prediction endpoints\",\n",
    "    \"Monitor and optimize storage costs in GCS\",\n",
    "    \"Use committed use discounts for predictable workloads\"\n",
    "]\n",
    "\n",
    "for tip in cost_tips:\n",
    "    print(f\"  üí° {tip}\")\n",
    "\n",
    "# Next steps roadmap\n",
    "print(f\"\\\\nüõ£Ô∏è  Next Steps Roadmap:\")\n",
    "next_steps = {\n",
    "    \"Phase 4.1 - Model Deployment\": [\n",
    "        \"Deploy best model to Vertex AI endpoint\",\n",
    "        \"Set up online prediction service\",\n",
    "        \"Implement batch prediction pipeline\",\n",
    "        \"Create model monitoring dashboard\"\n",
    "    ],\n",
    "    \n",
    "    \"Phase 4.2 - Pipeline Automation\": [\n",
    "        \"Build Vertex AI Pipelines workflow\",\n",
    "        \"Implement automated retraining\",\n",
    "        \"Set up model performance alerts\",\n",
    "        \"Create CI/CD for model deployment\"\n",
    "    ],\n",
    "    \n",
    "    \"Phase 4.3 - Advanced Features\": [\n",
    "        \"Implement feature stores\",\n",
    "        \"Set up model explainability\",\n",
    "        \"Add drift detection\",\n",
    "        \"Create ensemble models\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "for phase, tasks in next_steps.items():\n",
    "    print(f\"\\\\nüìã {phase}:\")\n",
    "    for i, task in enumerate(tasks, 1):\n",
    "        print(f\"  {i}. {task}\")\n",
    "\n",
    "# Save cloud training artifacts\n",
    "cloud_artifacts = {\n",
    "    'training_results': training_results,\n",
    "    'hyperparameter_results': tuning_results,\n",
    "    'comparison_analysis': comparison_df.to_dict() if 'comparison_df' in locals() else {},\n",
    "    'submitted_jobs': {\n",
    "        name: {\n",
    "            'job_id': getattr(job, 'job_id', str(job)),\n",
    "            'display_name': getattr(job, 'display_name', f\"{name}_job\"),\n",
    "            'state': getattr(job, 'state', 'COMPLETED')\n",
    "        } for name, job in submitted_jobs.items()\n",
    "    },\n",
    "    'metadata': {\n",
    "        'project_id': PROJECT_ID,\n",
    "        'location': LOCATION,\n",
    "        'staging_bucket': STAGING_BUCKET,\n",
    "        'notebook_run_time': datetime.now().isoformat(),\n",
    "        'phase': 'Phase 4 - Vertex AI Training'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save artifacts\n",
    "artifacts_path = CLOUD_DIR / f\"vertex_ai_artifacts_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "with open(artifacts_path, 'w') as f:\n",
    "    json.dump(cloud_artifacts, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\\\nüíæ Cloud Training Artifacts Saved:\")\n",
    "print(f\"   üìÑ File: {artifacts_path.name}\")\n",
    "print(f\"   üìä Training results: {len(training_results)} models\")\n",
    "print(f\"   üéõÔ∏è  Hyperparameter configs: {len(tuning_results)} configurations\")\n",
    "print(f\"   üìã Job submissions: {len(submitted_jobs)} jobs\")\n",
    "\n",
    "logger.info(f\"Vertex AI training artifacts saved to: {artifacts_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0088b504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Summary\n",
    "print(\"üéØ VERTEX AI TRAINING PIPELINE SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "notebook_end_time = datetime.now()\n",
    "# Note: start_time would be from the first cell\n",
    "execution_duration = \"N/A\"  # Would calculate from start_time if available\n",
    "\n",
    "print(f\"\\\\n‚è±Ô∏è  Pipeline Execution:\")\n",
    "print(f\"   üìÖ Completed: {notebook_end_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"   ‚è≥ Duration: {execution_duration}\")\n",
    "\n",
    "print(f\"\\\\n‚òÅÔ∏è  Cloud Configuration:\")\n",
    "print(f\"   üÜî Project ID: {PROJECT_ID}\")\n",
    "print(f\"   üåç Location: {LOCATION}\")\n",
    "print(f\"   üóÇÔ∏è  Staging Bucket: gs://{STAGING_BUCKET}\")\n",
    "\n",
    "print(f\"\\\\nüìä Training Summary:\")\n",
    "print(f\"   ü§ñ Models Trained: {len(training_results) if training_results else 0}\")\n",
    "print(f\"   üéõÔ∏è  Hyperparameter Configs: {len(tuning_results) if 'tuning_results' in locals() else 0}\")\n",
    "print(f\"   üìà Job Submissions: {len(submitted_jobs) if submitted_jobs else 0}\")\n",
    "\n",
    "if training_results:\n",
    "    successful_jobs = sum(1 for r in training_results.values() if r.get('state') == 'SUCCEEDED')\n",
    "    print(f\"   ‚úÖ Successful Jobs: {successful_jobs}/{len(training_results)}\")\n",
    "    \n",
    "    if successful_jobs > 0:\n",
    "        best_model_name = max(training_results.items(), \n",
    "                            key=lambda x: x[1].get('accuracy', 0))\n",
    "        print(f\"   üèÜ Best Model: {best_model_name[0]} ({best_model_name[1].get('accuracy', 0):.4f} accuracy)\")\n",
    "\n",
    "print(f\"\\\\nüíæ Artifacts Created:\")\n",
    "artifacts_created = [\n",
    "    \"Vertex AI training scripts and containers\",\n",
    "    \"Cloud training job configurations\", \n",
    "    \"Hyperparameter tuning results\",\n",
    "    \"Performance comparison analysis\",\n",
    "    \"Production best practices guide\",\n",
    "    \"Cloud training artifacts JSON\"\n",
    "]\n",
    "\n",
    "for artifact in artifacts_created:\n",
    "    print(f\"   üìÑ {artifact}\")\n",
    "\n",
    "print(f\"\\\\nüöÄ What's Next:\")\n",
    "next_actions = [\n",
    "    \"Review training results and select best model\",\n",
    "    \"Deploy selected model to Vertex AI endpoint (Phase 5)\",\n",
    "    \"Set up model monitoring and alerts\",\n",
    "    \"Implement automated retraining pipeline\",\n",
    "    \"Create production ML serving infrastructure\"\n",
    "]\n",
    "\n",
    "for i, action in enumerate(next_actions, 1):\n",
    "    print(f\"   {i}. {action}\")\n",
    "\n",
    "print(f\"\\\\nüìö Related Notebooks:\")\n",
    "notebook_sequence = [\n",
    "    (\"01_getting_started.ipynb\", \"Environment setup and configuration\"),\n",
    "    (\"02_data_processing_pipeline.ipynb\", \"Data preparation and preprocessing\"),\n",
    "    (\"03_model_training.ipynb\", \"Local model training and evaluation\"),\n",
    "    (\"04_vertex_ai_training.ipynb\", \"Current notebook - Cloud training\"),\n",
    "    (\"05_model_deployment.ipynb\", \"Model deployment and serving (Next)\"),\n",
    "    (\"06_vertex_ai_pipelines.ipynb\", \"Automated ML pipelines (Next)\")\n",
    "]\n",
    "\n",
    "for notebook, description in notebook_sequence:\n",
    "    status = \"‚úÖ Completed\" if notebook.startswith((\"01\", \"02\", \"03\", \"04\")) else \"‚è≥ Next\"\n",
    "    print(f\"   üìì {notebook}: {description} ({status})\")\n",
    "\n",
    "print(f\"\\\\n‚ú® Phase 4 - Vertex AI Training completed successfully!\")\n",
    "print(f\"üéØ Ready to proceed to Phase 5 - Model Deployment\")\n",
    "\n",
    "# Clean up resources\n",
    "plt.close('all')  # Close all matplotlib figures\n",
    "print(f\"\\\\nüßπ Resources cleaned up\")\n",
    "print(f\"üìù Vertex AI training notebook completed!\")\n",
    "\n",
    "logger.info(\"Vertex AI training pipeline completed successfully\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
